{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Kraken_ALTO_Colab_v5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761500761.0254314"
      },
      "source": [
        "\n",
        "# ðŸ“’ Kraken Training â€” **ALTO-only** (Colab, auto-flag detection, GPU/CPU)\n",
        "\n",
        "This notebook:\n",
        "- Assumes **ALTO** ground truth (eScriptorium exports)\n",
        "- Upload ZIPs â†’ auto-extract\n",
        "- Rebuilds `train.txt` / `val.txt`\n",
        "- **Auto-detects** Kraken CLI flags (older vs newer): `--lr` vs `--lrate`, `--validation` vs `--evaluation-files`\n",
        "- Uses Python `subprocess.run` (prints logs live)\n",
        "- Auto-selects GPU if available\n",
        "\n",
        "> In Colab: **Runtime â†’ Change runtime type â†’ GPU** first.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761500761.0254712"
      },
      "source": [
        "\n",
        "# 0) GPU check\n",
        "!nvidia-smi || true\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761500761.0254982"
      },
      "source": [
        "## 1) Install Kraken + deps (Py 3.12 / Colab-safe)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761500761.0255241"
      },
      "source": [
        "\n",
        "import sys, subprocess\n",
        "def pip_install(*pkgs):\n",
        "    print(\"pip install\", \" \".join(pkgs))\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *pkgs])\n",
        "# Colab-friendly pin (CLI may still be older depending on environment; we'll detect flags later)\n",
        "pip_install(\"kraken==5.3.0\", \"torch>=2.1,<3\", \"cairocffi\", \"opencv-python\", \"lxml\", \"h5py\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761500761.0255563"
      },
      "source": [
        "\n",
        "from importlib.metadata import version, PackageNotFoundError\n",
        "import shutil, torch, sys, subprocess\n",
        "\n",
        "def pkg_ver(name):\n",
        "    try: return version(name)\n",
        "    except PackageNotFoundError: return \"not installed\"\n",
        "\n",
        "print(\"python:\", sys.version.split()[0])\n",
        "print(\"kraken:\", pkg_ver(\"kraken\"))\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"cuda available:\", torch.cuda.is_available())\n",
        "print(\"ketos path:\", shutil.which(\"ketos\"))\n",
        "\n",
        "# Show a snippet of help to confirm CLI is reachable\n",
        "subprocess.run([\"ketos\", \"train\", \"--help\"], check=False)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761500761.0255919"
      },
      "source": [
        "## 2) Config â€” ALTO fixed, validation split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761500761.0256152"
      },
      "source": [
        "\n",
        "# ======= CONFIG (ALTO) =======\n",
        "FORMAT = \"alto\"     # hard-coded\n",
        "VAL_FRACTION = 0.10 # validation split\n",
        "# =============================\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761500761.025642"
      },
      "source": [
        "## 3) Upload ALTO ZIP(s) â€” auto-extract under /content/data_alto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761500761.0256784"
      },
      "source": [
        "\n",
        "import os, io, zipfile, re\n",
        "from google.colab import files\n",
        "\n",
        "LOCAL_BASE = \"/content/data_alto\"\n",
        "os.makedirs(LOCAL_BASE, exist_ok=True)\n",
        "\n",
        "print(\"Upload ALTO export ZIP(s). They will be extracted into\", LOCAL_BASE)\n",
        "uploaded = files.upload()\n",
        "\n",
        "EXTRACTED_ROOTS = []\n",
        "for name, data in uploaded.items():\n",
        "    path = os.path.join(LOCAL_BASE, name)\n",
        "    with open(path, \"wb\") as f: f.write(data)\n",
        "    if name.lower().endswith(\".zip\"):\n",
        "        base = re.sub(r\"\\s*\\(\\d+\\)\\s*$\", \"\", os.path.splitext(name)[0])\n",
        "        target = os.path.join(LOCAL_BASE, base)\n",
        "        os.makedirs(target, exist_ok=True)\n",
        "        with zipfile.ZipFile(io.BytesIO(data)) as zf:\n",
        "            zf.extractall(target)\n",
        "        os.remove(path)\n",
        "        EXTRACTED_ROOTS.append(target)\n",
        "    else:\n",
        "        EXTRACTED_ROOTS.append(LOCAL_BASE)\n",
        "\n",
        "print(\"Extracted roots:\")\n",
        "for r in EXTRACTED_ROOTS: print(\" -\", r if os.path.exists(r) else r+\" (missing)\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761500761.025706"
      },
      "source": [
        "## 4) Build ALTO XML list + write train/val files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761500761.0257294"
      },
      "source": [
        "\n",
        "import os, glob, random, pathlib, xml.etree.ElementTree as ET\n",
        "\n",
        "# Gather roots\n",
        "ROOTS = [r for r in EXTRACTED_ROOTS if r and os.path.exists(r)]\n",
        "assert ROOTS, \"No roots found. Upload a ZIP first and re-run.\"\n",
        "\n",
        "def is_alto_xml(path):\n",
        "    try:\n",
        "        r = ET.parse(path).getroot()\n",
        "        return isinstance(r.tag, str) and (\"alto\" in r.tag.lower())\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# Find XMLs (case-insensitive) and keep only ALTO\n",
        "xmls = []\n",
        "for root in ROOTS:\n",
        "    cands = glob.glob(os.path.join(root, \"**\", \"*.xml\"), recursive=True) +             glob.glob(os.path.join(root, \"**\", \"*.XML\"), recursive=True)\n",
        "    altos = [p for p in cands if is_alto_xml(p)]\n",
        "    print(f\"[ALTO] {len(altos):>5} XMLs in {root}\")\n",
        "    xmls.extend(altos)\n",
        "\n",
        "print(\"TOTAL ALTO XML files:\", len(xmls))\n",
        "assert len(xmls) >= 3, \"Need at least a few ALTO XML pages.\"\n",
        "\n",
        "# Train/val split\n",
        "random.seed(42)\n",
        "random.shuffle(xmls)\n",
        "n_val = max(1, int(len(xmls)*VAL_FRACTION))\n",
        "val_xmls = xmls[:n_val]\n",
        "train_xmls = xmls[n_val:]\n",
        "\n",
        "pathlib.Path(\"/content/lists\").mkdir(parents=True, exist_ok=True)\n",
        "open(\"/content/lists/train.txt\",\"w\").write(\"\\n\".join(train_xmls))\n",
        "open(\"/content/lists/val.txt\",\"w\").write(\"\\n\".join(val_xmls))\n",
        "\n",
        "print(\"Train pages:\", len(train_xmls), \"| Val pages:\", len(val_xmls))\n",
        "print(\"First train:\", train_xmls[:2])\n",
        "print(\"First val:\", val_xmls[:2])\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761500761.0257564"
      },
      "source": [
        "## 5) Hyperparameters (+ auto device) â€” edit learning rates here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761500761.0257788"
      },
      "source": [
        "\n",
        "# ======= EDIT ME (Hyperparameters) =======\n",
        "import torch, shutil\n",
        "\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n",
        "KETOS = shutil.which(\"ketos\") or \"ketos\"\n",
        "print(\"ketos path:\", KETOS)\n",
        "\n",
        "# Recognition\n",
        "REC_EPOCHS = 30\n",
        "REC_BATCH  = 8\n",
        "REC_OPTIM  = \"Adam\"    # or \"SGD\"\n",
        "REC_LR     = 0.0001    # learning rate (decimal allowed)\n",
        "REC_WD     = 1e-5\n",
        "\n",
        "# Segmentation\n",
        "SEG_EPOCHS = 20\n",
        "SEG_BATCH  = 2\n",
        "SEG_OPTIM  = \"Adam\"\n",
        "SEG_LR     = 0.0005    # learning rate\n",
        "# =========================================\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761500761.0258102"
      },
      "source": [
        "## 6) Helpers â€” detect Kraken flags and run training with logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761500761.0258405"
      },
      "source": [
        "\n",
        "import subprocess, shlex\n",
        "\n",
        "def detect_flags():\n",
        "    # Detect whether CLI supports --lr or --lrate; --validation or --evaluation-files\n",
        "    out = subprocess.run([KETOS, \"train\", \"--help\"], text=True, capture_output=True).stdout\n",
        "    lr_flag   = \"--lr\" if \"--lr\" in out else \"--lrate\"\n",
        "    val_flag  = \"--validation\" if \"--validation\" in out else \"--evaluation-files\"\n",
        "    print(f\"[detected] lr flag: {lr_flag}, validation flag: {val_flag}\")\n",
        "    return lr_flag, val_flag\n",
        "\n",
        "LR_FLAG, VAL_FLAG = detect_flags()\n",
        "\n",
        "def run_recognition(out_dir, epochs, batch, optim, lr, weight_decay, device, train_list, val_list):\n",
        "    args = [\n",
        "        KETOS, \"train\",\n",
        "        \"-f\", FORMAT, f\"@{train_list}\",\n",
        "        \"-o\", out_dir,\n",
        "        \"--device\", device,\n",
        "        \"--epochs\", str(epochs),\n",
        "        \"--batch-size\", str(batch),\n",
        "        \"--optimizer\", optim, LR_FLAG, str(lr), \"--weight-decay\", str(weight_decay),\n",
        "        VAL_FLAG, f\"@{val_list}\",\n",
        "    ]\n",
        "    print(\">>>\", \" \".join(shlex.quote(a) for a in args))\n",
        "    # stream logs live\n",
        "    return subprocess.run(args).returncode\n",
        "\n",
        "def run_segmentation(out_dir, epochs, batch, optim, lr, device, train_list, val_list):\n",
        "    args = [\n",
        "        KETOS, \"segtrain\",\n",
        "        \"-f\", FORMAT, f\"@{train_list}\",\n",
        "        \"-o\", out_dir,\n",
        "        \"--device\", device,\n",
        "        \"--epochs\", str(epochs),\n",
        "        \"--batch-size\", str(batch),\n",
        "        \"--optimizer\", optim, LR_FLAG, str(lr),\n",
        "        VAL_FLAG, f\"@{val_list}\",\n",
        "    ]\n",
        "    print(\">>>\", \" \".join(shlex.quote(a) for a in args))\n",
        "    return subprocess.run(args).returncode\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761500761.0258818"
      },
      "source": [
        "## 7) ðŸ”Ž Smoke test â€” recognition (1 epoch, tiny batch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761500761.0259151"
      },
      "source": [
        "\n",
        "rc = run_recognition(\n",
        "    out_dir=\"/content/models/rec_smoke\",\n",
        "    epochs=1, batch=2, optim=REC_OPTIM, lr=REC_LR, weight_decay=REC_WD,\n",
        "    device=\"cpu\",  # keep CPU for a fast sanity check\n",
        "    train_list=\"/content/lists/train.txt\",\n",
        "    val_list=\"/content/lists/val.txt\"\n",
        ")\n",
        "print(\"Return code:\", rc)\n",
        "assert rc == 0, \"Smoke test failed â€” check the printed logs above.\"\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761500761.0259526"
      },
      "source": [
        "## 8) â–¶ï¸ Recognition â€” full training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761500761.0259862"
      },
      "source": [
        "\n",
        "rc = run_recognition(\n",
        "    out_dir=\"/content/models/rec\",\n",
        "    epochs=REC_EPOCHS, batch=REC_BATCH, optim=REC_OPTIM, lr=REC_LR, weight_decay=REC_WD,\n",
        "    device=DEVICE,\n",
        "    train_list=\"/content/lists/train.txt\",\n",
        "    val_list=\"/content/lists/val.txt\"\n",
        ")\n",
        "print(\"Return code:\", rc)\n",
        "assert rc == 0, \"Recognition training failed.\"\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761500761.026025"
      },
      "source": [
        "## 9) â–¶ï¸ Segmentation â€” full training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761500761.0260541"
      },
      "source": [
        "\n",
        "rc = run_segmentation(\n",
        "    out_dir=\"/content/models/seg\",\n",
        "    epochs=SEG_EPOCHS, batch=SEG_BATCH, optim=SEG_OPTIM, lr=SEG_LR,\n",
        "    device=DEVICE,\n",
        "    train_list=\"/content/lists/train.txt\",\n",
        "    val_list=\"/content/lists/val.txt\"\n",
        ")\n",
        "print(\"Return code:\", rc)\n",
        "assert rc == 0, \"Segmentation training failed.\"\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761500761.026079"
      },
      "source": [
        "## 10) Evaluate recognition (CER/WER)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761500761.026102"
      },
      "source": [
        "\n",
        "import subprocess, shlex\n",
        "args = [\"ketos\", \"test\", \"-f\", FORMAT, \"/content/models/rec_best.mlmodel\", \"@/content/lists/val.txt\"]\n",
        "print(\">>>\", \" \".join(shlex.quote(a) for a in args))\n",
        "rc = subprocess.run(args).returncode\n",
        "print(\"Return code:\", rc)\n",
        "assert rc == 0, \"Evaluation failed.\"\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761500761.026126"
      },
      "source": [
        "## 11) Package models for download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761500761.026148"
      },
      "source": [
        "\n",
        "!mkdir -p /content/models && cd /content/models && ls -lh && zip -r ../trained_models.zip . && cd /content\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761500761.0261703"
      },
      "source": [
        "## 12) Optional â€” Upload to msia.escriptorium.fr via API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761500761.0261931"
      },
      "source": [
        "\n",
        "# UI upload (My Models â†’ Upload) is simplest.\n",
        "MSIA_URL   = \"https://msia.escriptorium.fr\"\n",
        "API_TOKEN  = \"PASTE_YOUR_TOKEN_HERE\"   # keep secret or leave blank\n",
        "MODEL_PATH = \"/content/models/rec_best.mlmodel\"   # or seg_best.mlmodel\n",
        "MODEL_NAME = \"rec_best\"\n",
        "\n",
        "if API_TOKEN and API_TOKEN != \"PASTE_YOUR_TOKEN_HERE\":\n",
        "    import requests\n",
        "    headers = {\"Authorization\": f\"Token {API_TOKEN}\"}\n",
        "    files = {\"file\": (MODEL_NAME + \".mlmodel\", open(MODEL_PATH, \"rb\"), \"application/octet-stream\")}\n",
        "    data  = {\"name\": MODEL_NAME}\n",
        "    resp = requests.post(f\"{MSIA_URL}/api/models/\", headers=headers, files=files, data=data)\n",
        "    print(\"Status:\", resp.status_code)\n",
        "    try:\n",
        "        print(resp.json())\n",
        "    except Exception:\n",
        "        print(resp.text[:800])\n",
        "else:\n",
        "    print(\"Skipping API upload. Use the UI or paste a valid API token.\")\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ]
}