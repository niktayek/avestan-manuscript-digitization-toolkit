{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Kraken_ALTO_Colab_v3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498778.222712"
      },
      "source": [
        "\n",
        "# ðŸ“’ Kraken Training on Colab â€” **ALTO** (Makefile-style, subprocess logging)\n",
        "\n",
        "This version:\n",
        "- Assumes **ALTO** ground truth (eScriptorium exports)\n",
        "- Auto-extracts uploaded ZIPs and discovers the roots\n",
        "- Uses **subprocess.run** for training so you **see full logs** (no `32512` confusion)\n",
        "- Lets you set learning rates/epochs/batch sizes in one place\n",
        "- Packs models for download and (optionally) POSTs to **msia.escriptorium.fr**\n",
        "\n",
        "> In Colab: **Runtime â†’ Change runtime type â†’ GPU** before running.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498778.222789"
      },
      "source": [
        "\n",
        "# 0) GPU check\n",
        "!nvidia-smi || true\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498778.222834"
      },
      "source": [
        "## 1) Install Kraken + deps (Python 3.12 safe)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498778.222859"
      },
      "source": [
        "\n",
        "import sys, subprocess\n",
        "\n",
        "def pip_install(*pkgs):\n",
        "    print(\"pip install\", \" \".join(pkgs))\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *pkgs])\n",
        "\n",
        "KR_PIN = \"kraken==5.3.0\"  # Colab-friendly default\n",
        "pip_install(KR_PIN, \"torch>=2.1,<3\", \"cairocffi\", \"opencv-python\", \"lxml\", \"h5py\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498778.222884"
      },
      "source": [
        "\n",
        "# Verify installs and CLI presence\n",
        "from importlib.metadata import version, PackageNotFoundError\n",
        "import torch, shutil, sys\n",
        "def pkg_ver(name):\n",
        "    try: return version(name)\n",
        "    except PackageNotFoundError: return \"not installed\"\n",
        "print(\"python:\", sys.version.split()[0])\n",
        "print(\"kraken:\", pkg_ver(\"kraken\"))\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"cuda available:\", torch.cuda.is_available())\n",
        "print(\"ketos on PATH:\", shutil.which(\"ketos\"))\n",
        "!ketos --version || true\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498778.222909"
      },
      "source": [
        "## 2) Config â€” ALTO fixed, split, and (optional) Drive roots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498778.222932"
      },
      "source": [
        "\n",
        "# ======= CONFIG (ALTO) =======\n",
        "FORMAT = \"alto\"  # hard-coded\n",
        "\n",
        "# Optional: add Drive roots if you also keep ALTO data on Drive\n",
        "DRIVE_ROOTS = [\n",
        "    # \"/content/drive/MyDrive/my_alto_export_folder\"\n",
        "]\n",
        "\n",
        "# Validation split fraction\n",
        "VAL_FRACTION = 0.10\n",
        "# =============================\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498778.222956"
      },
      "source": [
        "### (Optional) Mount Google Drive if you use DRIVE_ROOTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498778.222978"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498778.223"
      },
      "source": [
        "## 3) Upload ALTO ZIP(s) from Finder â€” auto-extract & discover roots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498778.223023"
      },
      "source": [
        "\n",
        "import os, io, zipfile, re\n",
        "from google.colab import files\n",
        "\n",
        "LOCAL_BASE = \"/content/data_alto\"\n",
        "os.makedirs(LOCAL_BASE, exist_ok=True)\n",
        "\n",
        "print(\"Upload one or more ALTO export ZIPs. They will be extracted into\", LOCAL_BASE)\n",
        "uploaded = files.upload()\n",
        "\n",
        "EXTRACTED_ROOTS = []\n",
        "for name, data in uploaded.items():\n",
        "    save_path = os.path.join(LOCAL_BASE, name)\n",
        "    with open(save_path, \"wb\") as f:\n",
        "        f.write(data)\n",
        "    if name.lower().endswith(\".zip\"):\n",
        "        base = re.sub(r\"\\s*\\(\\d+\\)\\s*$\", \"\", os.path.splitext(name)[0])\n",
        "        target_dir = os.path.join(LOCAL_BASE, base)\n",
        "        os.makedirs(target_dir, exist_ok=True)\n",
        "        with zipfile.ZipFile(io.BytesIO(data)) as zf:\n",
        "            zf.extractall(target_dir)\n",
        "        os.remove(save_path)\n",
        "        EXTRACTED_ROOTS.append(target_dir)\n",
        "    else:\n",
        "        EXTRACTED_ROOTS.append(LOCAL_BASE)\n",
        "\n",
        "print(\"Extracted roots:\", EXTRACTED_ROOTS if EXTRACTED_ROOTS else [\"(none; you can still use DRIVE_ROOTS)\"])\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498778.223049"
      },
      "source": [
        "## 4) Build merged ALTO XML list + sanity checks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498778.223072"
      },
      "source": [
        "\n",
        "import os, glob, xml.etree.ElementTree as ET\n",
        "\n",
        "ROOTS = [p for p in (EXTRACTED_ROOTS + DRIVE_ROOTS) if p and os.path.exists(p)]\n",
        "assert ROOTS, \"No existing roots found. Upload a ZIP or set DRIVE_ROOTS.\"\n",
        "\n",
        "def find_alto_xmls(root):\n",
        "    xmls = glob.glob(os.path.join(root, \"**\", \"*.xml\"), recursive=True) +            glob.glob(os.path.join(root, \"**\", \"*.XML\"), recursive=True)\n",
        "    out = []\n",
        "    for xp in xmls:\n",
        "        try:\n",
        "            r = ET.parse(xp).getroot()\n",
        "            if isinstance(r.tag, str) and \"alto\" in r.tag.lower():\n",
        "                out.append(xp)\n",
        "        except ET.ParseError:\n",
        "            pass\n",
        "    return sorted(out)\n",
        "\n",
        "xmls = []\n",
        "for root in ROOTS:\n",
        "    found = find_alto_xmls(root)\n",
        "    print(f\"[ALTO] {len(found):>5} XMLs in {root}\")\n",
        "    xmls.extend(found)\n",
        "\n",
        "print(\"TOTAL ALTO XML files:\", len(xmls))\n",
        "assert len(xmls) >= 3, \"Need at least a few ALTO XML pages.\"\n",
        "\n",
        "# Heuristic image presence check (by filename stem match)\n",
        "import collections\n",
        "stems = collections.Counter(os.path.splitext(os.path.basename(p))[0] for p in xmls)\n",
        "img_exts = {\".jpg\",\".jpeg\",\".tif\",\".tiff\",\".png\",\".jp2\",\".bmp\"}\n",
        "img_candidates = []\n",
        "for root in ROOTS:\n",
        "    for ext in img_exts:\n",
        "        img_candidates += glob.glob(os.path.join(root, \"**\", f\"*{ext}\"), recursive=True)\n",
        "img_stems = set(os.path.splitext(os.path.basename(p))[0] for p in img_candidates)\n",
        "missing = [s for s in stems if s not in img_stems]\n",
        "print(\"Heuristic: ALTO page stems without matching image file:\", len(missing))\n",
        "print(\"First few missing stems:\", missing[:10])\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498778.223102"
      },
      "source": [
        "## 5) Create explicit train/val lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498778.223125"
      },
      "source": [
        "\n",
        "import random, pathlib\n",
        "random.seed(42)\n",
        "\n",
        "random.shuffle(xmls)\n",
        "n_val = max(1, int(len(xmls)*VAL_FRACTION))\n",
        "val_xmls = xmls[:n_val]\n",
        "train_xmls = xmls[n_val:]\n",
        "\n",
        "pathlib.Path(\"/content/lists\").mkdir(parents=True, exist_ok=True)\n",
        "open(\"/content/lists/train.txt\",\"w\").write(\"\\n\".join(train_xmls))\n",
        "open(\"/content/lists/val.txt\",\"w\").write(\"\\n\".join(val_xmls))\n",
        "\n",
        "len(train_xmls), len(val_xmls)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498778.223154"
      },
      "source": [
        "## 6) Hyperparameters (+ auto device)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498778.223178"
      },
      "source": [
        "\n",
        "# ======= EDIT ME (Hyperparameters) =======\n",
        "import torch\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "# Recognition\n",
        "REC_EPOCHS = 30\n",
        "REC_BATCH  = 8\n",
        "REC_OPTIM  = \"Adam\"      # \"Adam\" or \"SGD\"\n",
        "REC_LR     = 0.0001      # change LR here (e.g., 0.00005)\n",
        "REC_WD     = 1e-5\n",
        "\n",
        "# Segmentation\n",
        "SEG_EPOCHS = 20\n",
        "SEG_BATCH  = 2\n",
        "SEG_OPTIM  = \"Adam\"\n",
        "SEG_LR     = 0.0005      # change LR here\n",
        "# =========================================\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498778.223203"
      },
      "source": [
        "### Helper: run a shell command with full logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498778.223227"
      },
      "source": [
        "\n",
        "import shutil, subprocess, textwrap\n",
        "\n",
        "KETOS = shutil.which(\"ketos\") or \"ketos\"\n",
        "\n",
        "def run_logged(cmd: str):\n",
        "    cmd = textwrap.dedent(cmd).strip()\n",
        "    print(\">>> Running:\\n\", cmd)\n",
        "    p = subprocess.run(cmd, shell=True, text=True)\n",
        "    print(\"<<< Return code:\", p.returncode)\n",
        "    return p.returncode\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498778.223253"
      },
      "source": [
        "## 7) Target: `train_seg` â€” Segmentation training (full logs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498778.223291"
      },
      "source": [
        "\n",
        "cmd = f'''\n",
        "{KETOS} segtrain -f {FORMAT} @/content/lists/train.txt   -o /content/models/seg   --device {DEVICE}   --epochs {SEG_EPOCHS}   --batch-size {SEG_BATCH}   --optimizer {SEG_OPTIM} --lr {SEG_LR}   --validation @/content/lists/val.txt\n",
        "'''\n",
        "rc = run_logged(cmd)\n",
        "assert rc == 0, \"segmentation training failed\"\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498778.223316"
      },
      "source": [
        "## 8) Target: `train_recog` â€” Recognition training (full logs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498778.22334"
      },
      "source": [
        "\n",
        "cmd = f'''\n",
        "{KETOS} train -f {FORMAT} @/content/lists/train.txt   -o /content/models/rec   --device {DEVICE}   --epochs {REC_EPOCHS}   --batch-size {REC_BATCH}   --optimizer {REC_OPTIM} --lr {REC_LR} --weight-decay {REC_WD}   --validation @/content/lists/val.txt\n",
        "'''\n",
        "rc = run_logged(cmd)\n",
        "assert rc == 0, \"recognition training failed\"\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498778.223363"
      },
      "source": [
        "## 9) Target: `eval` â€” Evaluate recognition (CER/WER)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498778.223386"
      },
      "source": [
        "\n",
        "cmd = f'''\n",
        "{KETOS} test -f {FORMAT} /content/models/rec_best.mlmodel @/content/lists/val.txt\n",
        "'''\n",
        "rc = run_logged(cmd)\n",
        "assert rc == 0, \"evaluation failed\"\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498778.22341"
      },
      "source": [
        "## 10) Package models for download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498778.223433"
      },
      "source": [
        "\n",
        "!cd /content/models && ls -lh && zip -r ../trained_models.zip . && cd /content\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498778.223456"
      },
      "source": [
        "## 11) Optional: Upload to msia.escriptorium.fr via API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498778.22348"
      },
      "source": [
        "\n",
        "# UI upload (My Models â†’ Upload) is simplest.\n",
        "# This cell shows how to POST a model programmatically if your instance supports it.\n",
        "MSIA_URL   = \"https://msia.escriptorium.fr\"\n",
        "API_TOKEN  = \"PASTE_YOUR_TOKEN_HERE\"   # keep secret; or leave blank and use UI upload\n",
        "MODEL_PATH = \"/content/models/rec_best.mlmodel\"   # or seg_best.mlmodel\n",
        "MODEL_NAME = \"rec_best\"\n",
        "\n",
        "if API_TOKEN and API_TOKEN != \"PASTE_YOUR_TOKEN_HERE\":\n",
        "    import requests\n",
        "    headers = {\"Authorization\": f\"Token {API_TOKEN}\"}\n",
        "    files = {\"file\": (MODEL_NAME + \".mlmodel\", open(MODEL_PATH, \"rb\"), \"application/octet-stream\")}\n",
        "    data  = {\"name\": MODEL_NAME}\n",
        "    resp = requests.post(f\"{MSIA_URL}/api/models/\", headers=headers, files=files, data=data)\n",
        "    print(\"Status:\", resp.status_code)\n",
        "    try:\n",
        "        print(resp.json())\n",
        "    except Exception:\n",
        "        print(resp.text[:800])\n",
        "else:\n",
        "    print(\"Skipping API upload. Use UI upload or paste a valid API token.\")\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ]
}