{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d2f9e28b",
      "metadata": {
        "id": "d2f9e28b"
      },
      "source": [
        "\n",
        "# Kraken + ALTO OCR ‚Äî Colab (Per‚ÄëManuscript Projects, Best‚ÄëModel Saver)\n",
        "\n",
        "This notebook keeps **everything per manuscript** inside a dedicated Drive folder and trains **recognition** models on ALTO data.\n",
        "\n",
        "**What you get**\n",
        "- One-time **Project ID** ‚Üí creates `MyDrive/kraken_projects/<PROJECT_ID>/`\n",
        "- Upload ALTO **ZIP** ‚Üí auto-extracts to `data/`\n",
        "- ALTO-first pairing ‚Üí writes `train.txt` and `val.txt` to `lists/`\n",
        "- **Controls** for: attempt number, learning rate, base model (previous/manual/auto-other)\n",
        "- Training uses **`-t`/`-e`** (Kraken 3) and after training **copies the best checkpoint** to\n",
        "  `models/rec/attempt_XX.mlmodel`\n",
        "- CPU speed tweaks, lean Drive usage (small pip cache)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d85603cc",
      "metadata": {
        "id": "d85603cc"
      },
      "source": [
        "## 1) Connect Google Drive\n",
        "This connects your Google Drive so the notebook can read/write your project files.\n",
        "You‚Äôll be asked to authorize once (click the link, choose your account, allow access).\n",
        "\n",
        "Outcome: Drive mounted at /content/drive.\n",
        "\n",
        "Tip: If you see a warning about ‚Äúalready mounted,‚Äù it‚Äôs fine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d25c6397",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d25c6397",
        "outputId": "30891e63-62af-4736-f0f2-91b844a37882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Drive mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive  # type: ignore\n",
        "drive.mount('/content/drive')\n",
        "print(\"‚úÖ Drive mounted at /content/drive\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55530f22",
      "metadata": {
        "id": "55530f22"
      },
      "source": [
        "\n",
        "## 2) Project Settings (edit only `PROJECT_ID`)\n",
        "\n",
        "- `PROJECT_ID`: your manuscript ID (e.g., `0093`).  \n",
        "This cell creates the project folder tree on Drive:\n",
        "```\n",
        "MyDrive/kraken_projects/<PROJECT_ID>/\n",
        "‚îú‚îÄ‚îÄ data/          # upload & extracted dataset (ALTO XML + images)\n",
        "‚îú‚îÄ‚îÄ lists/         # train.txt, val.txt\n",
        "‚îî‚îÄ‚îÄ models/\n",
        "    ‚îî‚îÄ‚îÄ rec/       # attempt_01.mlmodel, attempt_02.mlmodel, ...\n",
        "```\n",
        "\n",
        "What to edit: only the PROJECT_ID (your manuscript number, e.g., 0093).\n",
        "Outcome: Project folders created; paths printed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1e7c729d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e7c729d",
        "outputId": "3e8a530c-cadd-4226-a41b-ce3deb90fe4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Project folders ready\n",
            "PROJECT_DIR: /content/drive/MyDrive/kraken_projects/0093\n",
            "DATA_DIR: /content/drive/MyDrive/kraken_projects/0093/data\n",
            "LISTS_DIR: /content/drive/MyDrive/kraken_projects/0093/lists\n",
            "REC_MODELS: /content/drive/MyDrive/kraken_projects/0093/models/rec\n",
            "CPU_THREADS: 2 | CORES: 2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#@title üîß Project Settings\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "PROJECT_ID = \"0093\"  #@param {type:\"string\"}\n",
        "\n",
        "ROOT_IN_DRIVE = \"/content/drive/MyDrive\"\n",
        "PROJECTS_ROOT = f\"{ROOT_IN_DRIVE}/kraken_projects\"\n",
        "PROJECT_DIR   = f\"{PROJECTS_ROOT}/{PROJECT_ID}\"\n",
        "DATA_DIR      = f\"{PROJECT_DIR}/data\"\n",
        "LISTS_DIR     = f\"{PROJECT_DIR}/lists\"\n",
        "REC_MODELS    = f\"{PROJECT_DIR}/models/rec\"\n",
        "PIP_CACHE_DIR = f\"{ROOT_IN_DRIVE}/.pip-cache\"   # small cache only\n",
        "\n",
        "# Create the full project tree\n",
        "for p in [PROJECTS_ROOT, PROJECT_DIR, DATA_DIR, LISTS_DIR, REC_MODELS, PIP_CACHE_DIR]:\n",
        "    Path(p).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "TRAIN_LIST = f\"{LISTS_DIR}/train.txt\"\n",
        "VAL_LIST   = f\"{LISTS_DIR}/val.txt\"\n",
        "\n",
        "# CPU basics\n",
        "CORES = os.cpu_count() or 2\n",
        "CPU_THREADS = max(2, CORES - 1)\n",
        "DEVICE = \"cpu\"   # set \"cuda\" if you enable a T4 GPU in Colab\n",
        "\n",
        "print(\"‚úÖ Project folders ready\")\n",
        "print(\"PROJECT_DIR:\", PROJECT_DIR)\n",
        "print(\"DATA_DIR:\", DATA_DIR)\n",
        "print(\"LISTS_DIR:\", LISTS_DIR)\n",
        "print(\"REC_MODELS:\", REC_MODELS)\n",
        "print(\"CPU_THREADS:\", CPU_THREADS, \"| CORES:\", CORES)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76a2ad23",
      "metadata": {
        "id": "76a2ad23"
      },
      "source": [
        "## 3) CPU Speed Boost (threads & math libs)\n",
        "\n",
        "Sets thread/env variables so image and math libraries don‚Äôt oversubscribe CPU cores.\n",
        "Nothing to edit.\n",
        "Outcome: Printed thread settings (this can shave seconds on CPU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "cf90e4c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf90e4c7",
        "outputId": "88997dae-89e2-4ee2-de1f-99540e737cc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OMP_NUM_THREADS = 2\n",
            "MKL_NUM_THREADS = 2\n",
            "OPENBLAS_NUM_THREADS = 2\n",
            "NUMEXPR_NUM_THREADS = 2\n",
            "KMP_BLOCKTIME = 1\n",
            "KMP_AFFINITY = granularity=fine,compact,1,0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "os.environ[\"OMP_NUM_THREADS\"] = str(CPU_THREADS)\n",
        "os.environ[\"MKL_NUM_THREADS\"] = str(CPU_THREADS)\n",
        "os.environ[\"OPENBLAS_NUM_THREADS\"] = str(CPU_THREADS)\n",
        "os.environ[\"NUMEXPR_NUM_THREADS\"] = str(CPU_THREADS)\n",
        "os.environ[\"KMP_BLOCKTIME\"] = \"1\"\n",
        "os.environ[\"KMP_SETTINGS\"] = \"0\"\n",
        "os.environ[\"KMP_AFFINITY\"] = \"granularity=fine,compact,1,0\"\n",
        "\n",
        "for k in [\"OMP_NUM_THREADS\",\"MKL_NUM_THREADS\",\"OPENBLAS_NUM_THREADS\",\"NUMEXPR_NUM_THREADS\",\"KMP_BLOCKTIME\",\"KMP_AFFINITY\"]:\n",
        "    print(k, \"=\", os.environ.get(k))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55405fe0",
      "metadata": {
        "id": "55405fe0"
      },
      "source": [
        "## 4) Install Kraken (lean) + Pillow‚ÄëSIMD (faster image I/O)\n",
        "Installs Kraken OCR and a faster Pillow build for image I/O.\n",
        "The cell only installs if Kraken isn‚Äôt present.\n",
        "Nothing to edit.\n",
        "Outcome: ‚ÄúKraken available/installed‚Äù and ‚ÄúPillow-SIMD installed‚Äù."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "70ea2704",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70ea2704",
        "outputId": "3f0697d9-7f74-469b-db66-77c9856e4e7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Kraken available (version: unknown)\n",
            "‚è≥ Switching to Pillow-SIMD for faster image ops...\n",
            "‚úÖ Pillow-SIMD installed\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Install Kraken (lean) + Pillow-SIMD (faster image IO)\n",
        "\n",
        "import os, subprocess, sys\n",
        "\n",
        "# Lean pip settings\n",
        "os.environ[\"PIP_CACHE_DIR\"] = PIP_CACHE_DIR\n",
        "os.environ[\"PIP_DISABLE_PIP_VERSION_CHECK\"] = \"1\"\n",
        "os.environ[\"PIP_NO_INPUT\"] = \"1\"\n",
        "\n",
        "def is_importable(pkg: str) -> bool:\n",
        "    try:\n",
        "        __import__(pkg)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# Install kraken only if missing\n",
        "if is_importable(\"kraken\"):\n",
        "    import kraken\n",
        "    print(f\"‚úÖ Kraken available (version: {getattr(kraken, '__version__', 'unknown')})\")\n",
        "else:\n",
        "    print(\"‚è≥ Installing Kraken (lean) ...\")\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", \"--upgrade\", \"pip\"], check=True)\n",
        "    subprocess.run([\n",
        "        sys.executable, \"-m\", \"pip\", \"-q\", \"install\",\n",
        "        \"--prefer-binary\",\n",
        "        \"--upgrade-strategy\", \"only-if-needed\",\n",
        "        \"kraken[cairo]\"\n",
        "    ], check=True)\n",
        "    import kraken, importlib\n",
        "    importlib.reload(kraken)\n",
        "    print(f\"‚úÖ Installed Kraken (version: {getattr(kraken, '__version__', 'unknown')})\")\n",
        "\n",
        "# Switch to Pillow-SIMD for faster image decoding/resizing\n",
        "print(\"‚è≥ Switching to Pillow-SIMD for faster image ops...\")\n",
        "# Don't fail the whole cell if Pillow isn't present yet\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"-q\", \"uninstall\", \"-y\", \"pillow\"], check=False)\n",
        "subprocess.run([\n",
        "    sys.executable, \"-m\", \"pip\", \"-q\", \"install\",\n",
        "    \"--prefer-binary\",\n",
        "    \"--upgrade-strategy\", \"only-if-needed\",\n",
        "    \"pillow-simd\"\n",
        "], check=True)\n",
        "print(\"‚úÖ Pillow-SIMD installed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d00b6c2",
      "metadata": {
        "id": "6d00b6c2"
      },
      "source": [
        "## 5) Upload your ALTO dataset (ZIP ‚Üí Drive project folder)\n",
        "Upload your ZIP containing images and ALTO XML files.\n",
        "The ZIP is extracted into your project‚Äôs data/ folder on Drive.\n",
        "\n",
        "What to do: Click the upload button and pick your ZIP.\n",
        "Outcome: File listing of a few extracted files.\n",
        "\n",
        "Your ZIP should contain paired page images (e.g., .tif/.jpg) and ALTO XMLs. The XMLs must include <fileName> elements referring to the page image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6e23c5b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "6e23c5b0",
        "outputId": "38396dc7-1840-49b1-b538-2b8059bb3709"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Please select your ZIP (ALTO XML + images)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-14949184-c46a-464a-afbb-16506381cd2d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-14949184-c46a-464a-afbb-16506381cd2d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving export_doc5946_0093_alto_202510261625 2-20251119T220539Z-1-001.zip to export_doc5946_0093_alto_202510261625 2-20251119T220539Z-1-001 (2).zip\n",
            "‚úÖ Extracted into: /content/drive/MyDrive/kraken_projects/0093/data\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/export_doc5946_0093_alto_202510261625 2/0020_mirrored.xml\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/export_doc5946_0093_alto_202510261625 2/0025_mirrored.jpg\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/export_doc5946_0093_alto_202510261625 2/0023_mirrored.xml\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/export_doc5946_0093_alto_202510261625 2/0022_mirrored.xml\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/export_doc5946_0093_alto_202510261625 2/0026_mirrored.jpg\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/export_doc5946_0093_alto_202510261625 2/0023_mirrored.jpg\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/export_doc5946_0093_alto_202510261625 2/0024_mirrored.xml\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/export_doc5946_0093_alto_202510261625 2/0025_mirrored.xml\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/export_doc5946_0093_alto_202510261625 2/0022_mirrored.jpg\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/export_doc5946_0093_alto_202510261625 2/0020_mirrored.jpg\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/export_doc5946_0093_alto_202510261625 2/0024_mirrored.jpg\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/export_doc5946_0093_alto_202510261625 2/0021_mirrored.jpg\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/export_doc5946_0093_alto_202510261625 2/0026_mirrored.xml\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/export_doc5946_0093_alto_202510261625 2/0021_mirrored.xml\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/export_doc5946_0093_alto_202510261625 2/METS.xml\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import files  # type: ignore\n",
        "import zipfile, os\n",
        "\n",
        "print(\"üì¶ Please select your ZIP (ALTO XML + images)...\")\n",
        "uploaded = files.upload()\n",
        "if not uploaded:\n",
        "    raise SystemExit(\"‚ùå No file uploaded.\")\n",
        "\n",
        "zip_name = next(iter(uploaded.keys()))\n",
        "zip_path = f\"/content/{zip_name}\"\n",
        "\n",
        "# Extract into the Drive project data folder\n",
        "with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "    zf.extractall(DATA_DIR)\n",
        "\n",
        "print(f\"‚úÖ Extracted into: {DATA_DIR}\")\n",
        "!find \"$DATA_DIR\" -maxdepth 2 -type f | head -n 20\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9127fd6c",
      "metadata": {
        "id": "9127fd6c"
      },
      "source": [
        "## 6) Build train/val lists from ALTO (in project folder)\n",
        "Scans data/ for ALTO XMLs and writes:\n",
        "\t‚Ä¢\tlists/train.txt (90%)\n",
        "\t‚Ä¢\tlists/val.txt (10%)\n",
        "\n",
        "Important: For -f alto, lists must contain only XML file paths, one per line‚Äîno image paths.\n",
        "Outcome: Counts printed + a short sample of each list.\n",
        "\n",
        "If it says ‚ÄúNot enough ALTO XMLs‚Äù or shows missing files, check your ZIP structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e0bb1878",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0bb1878",
        "outputId": "a567e0de-ddd7-47cc-e271-805e11c1aae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7 ALTO XML files.\n",
            "‚úÖ Wrote lists:\n",
            "  - /content/drive/MyDrive/kraken_projects/0093/lists/train.txt: 6\n",
            "  - /content/drive/MyDrive/kraken_projects/0093/lists/val.txt:   1\n",
            "\n",
            "Sample from /content/drive/MyDrive/kraken_projects/0093/lists/train.txt:\n",
            "   /content/drive/MyDrive/kraken_projects/0093/data/export_doc5946_0093_alto_202510261625 2/0021_mirrored.xml\n",
            "   /content/drive/MyDrive/kraken_projects/0093/data/export_doc5946_0093_alto_202510261625 2/0023_mirrored.xml\n",
            "   /content/drive/MyDrive/kraken_projects/0093/data/export_doc5946_0093_alto_202510261625 2/0024_mirrored.xml\n",
            "   /content/drive/MyDrive/kraken_projects/0093/data/export_doc5946_0093_alto_202510261625 2/0022_mirrored.xml\n",
            "   /content/drive/MyDrive/kraken_projects/0093/data/export_doc5946_0093_alto_202510261625 2/0026_mirrored.xml\n",
            "\n",
            "Sample from /content/drive/MyDrive/kraken_projects/0093/lists/val.txt:\n",
            "   /content/drive/MyDrive/kraken_projects/0093/data/export_doc5946_0093_alto_202510261625 2/0025_mirrored.xml\n"
          ]
        }
      ],
      "source": [
        "# Build train/val lists for ALTO: ONE XML PATH PER LINE (no image paths)\n",
        "\n",
        "from pathlib import Path\n",
        "import xml.etree.ElementTree as ET\n",
        "import random, os\n",
        "\n",
        "random.seed(42)  # reproducible split\n",
        "\n",
        "DATA_DIR = DATA_DIR  # already defined\n",
        "LISTS_DIR = LISTS_DIR\n",
        "TRAIN_LIST = TRAIN_LIST\n",
        "VAL_LIST = VAL_LIST\n",
        "\n",
        "def is_alto_xml(p: Path) -> bool:\n",
        "    if p.suffix.lower() != \".xml\" or not p.is_file():\n",
        "        return False\n",
        "    try:\n",
        "        # quick scan first\n",
        "        with open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\") as fh:\n",
        "            head = fh.read(4096)\n",
        "            if \"<alto\" not in head:\n",
        "                return False\n",
        "        # light parse to be safe\n",
        "        ET.parse(p)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# Collect all ALTO XMLs under DATA_DIR\n",
        "xmls = [p for p in Path(DATA_DIR).rglob(\"*.xml\") if is_alto_xml(p)]\n",
        "xmls = sorted({x.resolve() for x in xmls})  # dedup + sort\n",
        "\n",
        "n = len(xmls)\n",
        "print(f\"Found {n} ALTO XML files.\")\n",
        "\n",
        "if n < 2:\n",
        "    raise SystemExit(f\"‚ùå Not enough ALTO XMLs in {DATA_DIR}. Found {n}.\")\n",
        "\n",
        "# 90/10 split, shuffled\n",
        "random.shuffle(xmls)\n",
        "cut = max(1, int(n * 0.9))\n",
        "train_xmls, val_xmls = xmls[:cut], xmls[cut:]\n",
        "\n",
        "Path(LISTS_DIR).mkdir(parents=True, exist_ok=True)\n",
        "with open(TRAIN_LIST, \"w\", encoding=\"utf-8\") as f:\n",
        "    for x in train_xmls:\n",
        "        f.write(str(x) + \"\\n\")\n",
        "with open(VAL_LIST, \"w\", encoding=\"utf-8\") as f:\n",
        "    for x in val_xmls:\n",
        "        f.write(str(x) + \"\\n\")\n",
        "\n",
        "print(f\"‚úÖ Wrote lists:\")\n",
        "print(f\"  - {TRAIN_LIST}: {len(train_xmls)}\")\n",
        "print(f\"  - {VAL_LIST}:   {len(val_xmls)}\")\n",
        "\n",
        "# quick sanity check\n",
        "def show_sample(fp, k=5):\n",
        "    print(f\"\\nSample from {fp}:\")\n",
        "    with open(fp, encoding=\"utf-8\") as fh:\n",
        "        for i, line in enumerate(fh):\n",
        "            if i >= k: break\n",
        "            print(\"  \", line.strip())\n",
        "show_sample(TRAIN_LIST)\n",
        "show_sample(VAL_LIST)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76765693",
      "metadata": {
        "id": "76765693"
      },
      "source": [
        "\n",
        "## 7) Training Controls\n",
        "\n",
        "Choose your attempt, learning rate, and base model source:\n",
        "\t‚Ä¢\tBASE_SOURCE = choose ‚Üí type the attempt number to load from this manuscript (e.g., 13).\n",
        "\t‚Ä¢\tBASE_SOURCE = upload ‚Üí you‚Äôll upload a .mlmodel as base.\n",
        "\n",
        "Inputs to fill:\n",
        "\t‚Ä¢\tATTEMPT_ID, LEARNING_RATE, BASE_SOURCE, and if needed BASE_ATTEMPT_TO_LOAD.\n",
        "Outcome: The chosen values are printed for confirmation.\n",
        "\n",
        "Tip: On CPU, try BATCH_SIZE = 32 (bump to 48/64 if it fits).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "9b07f678",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b07f678",
        "outputId": "afa855db-67c2-4fdd-b8a4-d11dea924ae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ATTEMPT_ID: 1\n",
            "LEARNING_RATE: 0.0001\n",
            "BASE_SOURCE: upload\n",
            "BASE_ATTEMPT_TO_LOAD: None\n"
          ]
        }
      ],
      "source": [
        "#@title üß≠ Training Controls (choose or upload a base; no paths)\n",
        "ATTEMPT_ID = 1            #@param {type:\"number\"}\n",
        "LEARNING_RATE = 0.0001     #@param {type:\"number\"}  # set to 0 to use Kraken default\n",
        "BASE_SOURCE = \"upload\"     #@param [\"choose\", \"upload\"]\n",
        "BASE_ATTEMPT_TO_LOAD = None  #@param {type:\"number\"}  # attempt to load if BASE_SOURCE=\"choose\"\n",
        "\n",
        "# Early stopping\n",
        "EARLY_STOP = \"early\"       #@param [\"early\", \"dumb\"]\n",
        "LAG_EPOCHS = 6             #@param {type:\"number\"}\n",
        "MIN_DELTA = 0.0001         #@param {type:\"number\"}\n",
        "\n",
        "# CPU perf\n",
        "import os\n",
        "BATCH_SIZE = min(32, max(8, (os.cpu_count() or 2) * 2))\n",
        "\n",
        "# Normalize LR (0 => None to use Kraken default)\n",
        "LEARNING_RATE = None if (LEARNING_RATE == 0) else LEARNING_RATE\n",
        "\n",
        "print(\"ATTEMPT_ID:\", ATTEMPT_ID)\n",
        "print(\"LEARNING_RATE:\", LEARNING_RATE)\n",
        "print(\"BASE_SOURCE:\", BASE_SOURCE)\n",
        "print(\"BASE_ATTEMPT_TO_LOAD:\", BASE_ATTEMPT_TO_LOAD)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MPnrHdbOZW6l",
      "metadata": {
        "id": "MPnrHdbOZW6l"
      },
      "source": [
        "## üîó Resolve Base Model (STRICT: choose attempt or upload; no fallback)\n",
        "Picks the base .mlmodel automatically without asking for paths:\n",
        "\t‚Ä¢\tIf choose, it loads attempt_XX.mlmodel from this manuscript‚Äôs models/rec/.\n",
        "\t‚Ä¢\tIf upload, it opens a file picker and saves your upload to the right place.\n",
        "\n",
        "Outcome: Prints the exact BASE_MODEL path. If a chosen attempt isn‚Äôt found, it lists available attempts.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "rjKFQxjOYiX0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "rjKFQxjOYiX0",
        "outputId": "b1fb0845-120a-47a3-b206-8c13af5bc0c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì§ Upload a .mlmodel file to use as base‚Ä¶\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1dfd4312-1f79-4d00-905b-780ed1babdb6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1dfd4312-1f79-4d00-905b-780ed1babdb6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 0088-recognizer-02.mlmodel to 0088-recognizer-02.mlmodel\n",
            "‚úÖ Uploaded base to: /content/drive/MyDrive/kraken_projects/0093/models/rec/0088-recognizer-02.mlmodel\n",
            "\n",
            "‚úÖ BASE_MODEL resolved as: /content/drive/MyDrive/kraken_projects/0093/models/rec/0088-recognizer-02.mlmodel\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from google.colab import files  # type: ignore\n",
        "import shutil\n",
        "\n",
        "# Clear any stale value\n",
        "if 'BASE_MODEL' in globals():\n",
        "    del BASE_MODEL\n",
        "\n",
        "def list_available_attempts(rec_dir: str):\n",
        "    recp = Path(rec_dir)\n",
        "    found = sorted(p for p in recp.glob(\"attempt_*.mlmodel\"))\n",
        "    if not found:\n",
        "        print(\"‚ÑπÔ∏è No attempts found yet in\", recp)\n",
        "        return\n",
        "    print(\"Available attempts in this manuscript:\")\n",
        "    for p in found:\n",
        "        print(\"  ‚Ä¢\", p.name)\n",
        "\n",
        "def upload_model_to_drive(dest_dir: str) -> str:\n",
        "    print(\"üì§ Upload a .mlmodel file to use as base‚Ä¶\")\n",
        "    up = files.upload()\n",
        "    if not up:\n",
        "        raise SystemExit(\"‚ùå No file uploaded.\")\n",
        "    fname = next(iter(up.keys()))\n",
        "    src = f\"/content/{fname}\"\n",
        "    dest = str(Path(dest_dir) / Path(fname).name)\n",
        "    shutil.move(src, dest)\n",
        "    print(f\"‚úÖ Uploaded base to: {dest}\")\n",
        "    return dest\n",
        "\n",
        "BASE_MODEL = None\n",
        "\n",
        "if BASE_SOURCE == \"choose\":\n",
        "    chosen = Path(REC_MODELS) / f\"attempt_{int(BASE_ATTEMPT_TO_LOAD):02d}.mlmodel\"\n",
        "    if chosen.exists():\n",
        "        BASE_MODEL = str(chosen.resolve())\n",
        "        print(\"Base = chosen attempt:\", BASE_MODEL)\n",
        "    else:\n",
        "        print(f\"‚ùå attempt_{int(BASE_ATTEMPT_TO_LOAD):02d}.mlmodel not found in {REC_MODELS}.\")\n",
        "        list_available_attempts(REC_MODELS)\n",
        "        raise SystemExit(\"Change BASE_ATTEMPT_TO_LOAD or switch to BASE_SOURCE='upload'.\")\n",
        "\n",
        "elif BASE_SOURCE == \"upload\":\n",
        "    BASE_MODEL = upload_model_to_drive(REC_MODELS)\n",
        "\n",
        "print(\"\\n‚úÖ BASE_MODEL resolved as:\", BASE_MODEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZNRXaGczgaZI",
      "metadata": {
        "id": "ZNRXaGczgaZI"
      },
      "source": [
        "## Stage ALTO dataset locally (XMLs + images; rewrite <fileName>)\n",
        "Copies each XML in the lists and its linked image to local disk (/content/alto_staged/data/), then rewrites the XML‚Äôs <fileName> to the local image name. This removes Google Drive latency.\n",
        "\n",
        "Nothing to edit.\n",
        "Outcome: Creates:\n",
        "\t‚Ä¢\tLOCAL_TRAIN_LIST and LOCAL_VAL_LIST with updated local XML paths\n",
        "\t‚Ä¢\tA count of staged entries\n",
        "\n",
        "On CPU, this is the biggest speed boost. On GPU, it‚Äôs optional (still helps a bit).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "h5frN8T4gWNd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5frN8T4gWNd",
        "outputId": "22a99fcc-2166-4f80-d1eb-b858709b9768"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Staged 6 / 6 ‚Üí /content/alto_staged/train_local.txt\n",
            "‚úÖ Staged 1 / 1 ‚Üí /content/alto_staged/val_local.txt\n",
            "\n",
            "Local staged dataset:\n",
            "  Root: /content/alto_staged\n",
            "  Data dir: /content/alto_staged/data\n",
            "  TRAIN (local): /content/alto_staged/train_local.txt  | entries: 6\n",
            "  VAL   (local): /content/alto_staged/val_local.txt  | entries: 1\n",
            "\n",
            "üëâ In your training cell set: _USE_LOCAL = True\n"
          ]
        }
      ],
      "source": [
        "#@title üöÄ Stage ALTO dataset locally (XMLs + images; rewrite <fileName>)\n",
        "# Copies XMLs referenced by TRAIN_LIST/VAL_LIST to /content/alto_staged/data,\n",
        "# copies their linked images next to them, and rewrites <fileName> in the\n",
        "# copied XML to the copied image basename. Produces LOCAL_TRAIN_LIST/LOCAL_VAL_LIST.\n",
        "\n",
        "from pathlib import Path\n",
        "import xml.etree.ElementTree as ET\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Inputs from earlier cells:\n",
        "# - TRAIN_LIST, VAL_LIST (XML-only lists)\n",
        "# Outputs from this cell:\n",
        "LOCAL_ROOT = Path(\"/content/alto_staged\")\n",
        "DATA_OUT   = LOCAL_ROOT / \"data\"\n",
        "LOCAL_TRAIN_LIST = str(LOCAL_ROOT / \"train_local.txt\")\n",
        "LOCAL_VAL_LIST   = str(LOCAL_ROOT / \"val_local.txt\")\n",
        "\n",
        "DATA_OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def _localname(tag: str) -> str:\n",
        "    \"\"\"Strip XML namespace from tag like {ns}tag ‚Üí tag.\"\"\"\n",
        "    return tag.split('}', 1)[1] if '}' in tag else tag\n",
        "\n",
        "def _find_alto_filename(root: ET.Element) -> str | None:\n",
        "    \"\"\"Return text of first <fileName> element, or None.\"\"\"\n",
        "    for el in root.iter():\n",
        "        if _localname(el.tag) == \"fileName\":\n",
        "            if el.text and el.text.strip():\n",
        "                return el.text.strip()\n",
        "    return None\n",
        "\n",
        "def _resolve_image(xml_path: Path, file_name_text: str) -> Path | None:\n",
        "    \"\"\"\n",
        "    Resolve the image path referenced by an ALTO <fileName>.\n",
        "    Try: (xml_dir / file_name), then search by basename around xml_dir.\n",
        "    \"\"\"\n",
        "    cand = (xml_path.parent / file_name_text)\n",
        "    if cand.exists():\n",
        "        return cand.resolve()\n",
        "    # Fallback: search by just the name (handles absolute or weird rel paths written into <fileName>)\n",
        "    base = Path(file_name_text).name\n",
        "    for p in xml_path.parent.rglob(base):\n",
        "        if p.exists() and p.is_file():\n",
        "            return p.resolve()\n",
        "    return None\n",
        "\n",
        "def _copy_with_rewrite(xml_in: Path, dst_dir: Path) -> Path | None:\n",
        "    \"\"\"\n",
        "    Copy xml_in and its linked image into dst_dir, rewrite <fileName> to point to copied image basename.\n",
        "    Return path to copied XML, or None if image can‚Äôt be resolved.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # quick header sanity\n",
        "        with open(xml_in, \"r\", encoding=\"utf-8\", errors=\"ignore\") as fh:\n",
        "            if \"<alto\" not in fh.read(4096):\n",
        "                print(f\"‚ö†Ô∏è Not ALTO (skip): {xml_in}\")\n",
        "                return None\n",
        "\n",
        "        tree = ET.parse(xml_in)\n",
        "        root = tree.getroot()\n",
        "        fn_text = _find_alto_filename(root)\n",
        "        if not fn_text:\n",
        "            print(f\"‚ö†Ô∏è No <fileName> in: {xml_in}\")\n",
        "            return None\n",
        "\n",
        "        img_in = _resolve_image(xml_in, fn_text)\n",
        "        if not img_in:\n",
        "            print(f\"‚ö†Ô∏è Image not found for: {xml_in}  (<fileName>={fn_text})\")\n",
        "            return None\n",
        "\n",
        "        # Prepare destinations\n",
        "        dst_dir.mkdir(parents=True, exist_ok=True)\n",
        "        xml_out = dst_dir / xml_in.name\n",
        "        img_out = dst_dir / img_in.name\n",
        "\n",
        "        # Copy image (first) and xml\n",
        "        if not img_out.exists():\n",
        "            shutil.copy2(img_in, img_out)\n",
        "\n",
        "        # Rewrite <fileName> to local basename\n",
        "        for el in root.iter():\n",
        "            if _localname(el.tag) == \"fileName\":\n",
        "                el.text = img_out.name\n",
        "                break\n",
        "\n",
        "        tree.write(xml_out, encoding=\"utf-8\", xml_declaration=True)\n",
        "        return xml_out\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Failed on {xml_in}: {e}\")\n",
        "        return None\n",
        "\n",
        "def _collect_xmls(list_file: str) -> list[Path]:\n",
        "    out: list[Path] = []\n",
        "    with open(list_file, encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            p = Path(line.strip())\n",
        "            if p.suffix.lower() == \".xml\" and p.is_file():\n",
        "                out.append(p.resolve())\n",
        "            else:\n",
        "                # ignore empties/non-xmls silently\n",
        "                if line.strip():\n",
        "                    # print(f\"‚ÑπÔ∏è Skipping non-XML or missing: {line.strip()}\")\n",
        "                    pass\n",
        "    return out\n",
        "\n",
        "def _stage_list(orig_list: str, new_list: str) -> int:\n",
        "    staged = []\n",
        "    xmls = _collect_xmls(orig_list)\n",
        "    for i, xml_in in enumerate(xmls, 1):\n",
        "        xml_out = _copy_with_rewrite(xml_in, DATA_OUT)\n",
        "        if xml_out:\n",
        "            staged.append(str(xml_out))\n",
        "        # Small progress ping every ~200 files\n",
        "        if i % 200 == 0:\n",
        "            print(f\"‚Ä¶ staged {i}/{len(xmls)}\")\n",
        "    with open(new_list, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\\n\".join(staged) + \"\\n\")\n",
        "    print(f\"‚úÖ Staged {len(staged)} / {len(xmls)} ‚Üí {new_list}\")\n",
        "    return len(staged)\n",
        "\n",
        "# Run staging for train/val\n",
        "LOCAL_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "n_tr = _stage_list(TRAIN_LIST, LOCAL_TRAIN_LIST)\n",
        "n_va = _stage_list(VAL_LIST,   LOCAL_VAL_LIST)\n",
        "\n",
        "print(\"\\nLocal staged dataset:\")\n",
        "print(\"  Root:\", LOCAL_ROOT)\n",
        "print(\"  Data dir:\", DATA_OUT)\n",
        "print(\"  TRAIN (local):\", LOCAL_TRAIN_LIST, \" | entries:\", n_tr)\n",
        "print(\"  VAL   (local):\", LOCAL_VAL_LIST,   \" | entries:\", n_va)\n",
        "print(\"\\nüëâ In your training cell set: _USE_LOCAL = True\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e17be092",
      "metadata": {
        "id": "e17be092"
      },
      "source": [
        "\n",
        "## 8) Train recognition (best checkpoint ‚Üí `attempt_XX.mlmodel`)\n",
        "\n",
        "Trains with live logs (you‚Äôll see epochs and metrics as they happen).\n",
        "The best checkpoint is saved as:\n",
        "MyDrive/kraken_projects/<PROJECT_ID>/models/rec/attempt_XX.mlmodel\n",
        "\n",
        "What to check before running:\n",
        "\t‚Ä¢\tBASE_MODEL is printed correctly (from ‚ÄúResolve Base Model‚Äù).\n",
        "\t‚Ä¢\t_USE_LOCAL = True if you ran ‚ÄúStage ALTO‚Äù (recommended on CPU).\n",
        "\n",
        "Outcome: Live training logs; at the end you‚Äôll see ‚ÄúSaved best checkpoint as ‚Ä¶‚Äù.\n",
        "\n",
        "Slow on CPU? Use staging, increase BATCH_SIZE, validate less often (set -F 2), or switch Colab runtime to GPU (T4)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "8b9e707d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8b9e707d",
        "outputId": "ec827b1b-3c65-4062-dbbe-a4dde88f212d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Project ID:      0093\n",
            "üìÇ BASE_DIR:        /content/drive/MyDrive/kraken_projects/0093\n",
            "üìÑ Train list:      /content/drive/MyDrive/kraken_projects/0093/lists/train.txt\n",
            "üìÑ Val list:        /content/drive/MyDrive/kraken_projects/0093/lists/val.txt\n",
            "üì¶ Output prefix:   /content/drive/MyDrive/kraken_projects/0093/models/rec/attempt_01\n",
            "üß† Base model:      /content/drive/MyDrive/kraken_projects/0093/models/rec/0088-recognizer-02.mlmodel\n",
            "\n",
            "Running:\n",
            "ketos train -o /content/drive/MyDrive/kraken_projects/0093/models/rec/attempt_01 -f alto -t\n",
            "/content/drive/MyDrive/kraken_projects/0093/lists/train.txt -e /content/drive/MyDrive/kraken_projects/0093/lists/val.txt\n",
            "-q early --lag 6 --min-delta 0.0001 -B 8 -F 1 -i\n",
            "/content/drive/MyDrive/kraken_projects/0093/models/rec/0088-recognizer-02.mlmodel --resize add -r 0.0001\n",
            "--------------------------------------------------------------------------------\n",
            "2025-11-19 22:43:36.670544: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763592216.695780    9872 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763592216.703477    9872 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763592216.723519    9872 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763592216.723568    9872 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763592216.723571    9872 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763592216.723573    9872 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-19 22:43:36.729648: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[11/19/25 22:43:45] WARNING  alphabet mismatch: chars in training   train.py:428\n",
            "                             set only: {'Ãä', '≈´', 'j', 'Ã∞', 'o', 'k',             \n",
            "                             'Ãå', '·π£'} (not included in accuracy                 \n",
            "                             test during training)                              \n",
            "WARNING:kraken.lib.train:alphabet mismatch: chars in training set only: {'Ãä', '≈´', 'j', 'Ã∞', 'o', 'k', 'Ãå', '·π£'} (not included in accuracy test during training)\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
            "                    WARNING  Neural network has been trained on     train.py:639\n",
            "                             mode L images, training set contains               \n",
            "                             mode 1 data. Consider setting                      \n",
            "                             `force_binarization`                               \n",
            "WARNING:kraken.lib.train:Neural network has been trained on mode L images, training set contains mode 1 data. Consider setting `force_binarization`\n",
            "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
            "‚îÉ    ‚îÉ Name      ‚îÉ Type         ‚îÉ Params ‚îÉ Mode  ‚îÉ     In sizes ‚îÉ    Out sizes ‚îÉ\n",
            "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
            "‚îÇ 0  ‚îÇ val_cer   ‚îÇ CharErrorRa‚Ä¶ ‚îÇ      0 ‚îÇ train ‚îÇ            ? ‚îÇ            ? ‚îÇ\n",
            "‚îÇ 1  ‚îÇ val_wer   ‚îÇ WordErrorRa‚Ä¶ ‚îÇ      0 ‚îÇ train ‚îÇ            ? ‚îÇ            ? ‚îÇ\n",
            "‚îÇ 2  ‚îÇ net       ‚îÇ MultiParamS‚Ä¶ ‚îÇ  4.0 M ‚îÇ train ‚îÇ [[1, 1, 120, ‚îÇ  [[1, 60, 1, ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ   400], '?'] ‚îÇ    50], '?'] ‚îÇ\n",
            "‚îÇ 3  ‚îÇ net.C_0   ‚îÇ ActConv2D    ‚îÇ  1.3 K ‚îÇ train ‚îÇ [[1, 1, 120, ‚îÇ     [[1, 32, ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ   400], '?', ‚îÇ   120, 400], ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ         '?'] ‚îÇ         '?'] ‚îÇ\n",
            "‚îÇ 4  ‚îÇ net.Do_1  ‚îÇ Dropout      ‚îÇ      0 ‚îÇ train ‚îÇ     [[1, 32, ‚îÇ     [[1, 32, ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ   120, 400], ‚îÇ   120, 400], ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ    '?', '?'] ‚îÇ         '?'] ‚îÇ\n",
            "‚îÇ 5  ‚îÇ net.Mp_2  ‚îÇ MaxPool      ‚îÇ      0 ‚îÇ train ‚îÇ     [[1, 32, ‚îÇ [[1, 32, 60, ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ   120, 400], ‚îÇ   200], '?'] ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ    '?', '?'] ‚îÇ              ‚îÇ\n",
            "‚îÇ 6  ‚îÇ net.C_3   ‚îÇ ActConv2D    ‚îÇ 40.0 K ‚îÇ train ‚îÇ [[1, 32, 60, ‚îÇ [[1, 32, 60, ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ   200], '?', ‚îÇ   200], '?'] ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ         '?'] ‚îÇ              ‚îÇ\n",
            "‚îÇ 7  ‚îÇ net.Do_4  ‚îÇ Dropout      ‚îÇ      0 ‚îÇ train ‚îÇ [[1, 32, 60, ‚îÇ [[1, 32, 60, ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ   200], '?', ‚îÇ   200], '?'] ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ         '?'] ‚îÇ              ‚îÇ\n",
            "‚îÇ 8  ‚îÇ net.Mp_5  ‚îÇ MaxPool      ‚îÇ      0 ‚îÇ train ‚îÇ [[1, 32, 60, ‚îÇ [[1, 32, 30, ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ   200], '?', ‚îÇ   100], '?'] ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ         '?'] ‚îÇ              ‚îÇ\n",
            "‚îÇ 9  ‚îÇ net.C_6   ‚îÇ ActConv2D    ‚îÇ 55.4 K ‚îÇ train ‚îÇ [[1, 32, 30, ‚îÇ [[1, 64, 30, ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ   100], '?', ‚îÇ   100], '?'] ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ         '?'] ‚îÇ              ‚îÇ\n",
            "‚îÇ 10 ‚îÇ net.Do_7  ‚îÇ Dropout      ‚îÇ      0 ‚îÇ train ‚îÇ [[1, 64, 30, ‚îÇ [[1, 64, 30, ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ   100], '?', ‚îÇ   100], '?'] ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ         '?'] ‚îÇ              ‚îÇ\n",
            "‚îÇ 11 ‚îÇ net.Mp_8  ‚îÇ MaxPool      ‚îÇ      0 ‚îÇ train ‚îÇ [[1, 64, 30, ‚îÇ [[1, 64, 15, ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ   100], '?', ‚îÇ    50], '?'] ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ         '?'] ‚îÇ              ‚îÇ\n",
            "‚îÇ 12 ‚îÇ net.C_9   ‚îÇ ActConv2D    ‚îÇ  110 K ‚îÇ train ‚îÇ [[1, 64, 15, ‚îÇ [[1, 64, 15, ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ    50], '?', ‚îÇ    50], '?'] ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ         '?'] ‚îÇ              ‚îÇ\n",
            "‚îÇ 13 ‚îÇ net.Do_10 ‚îÇ Dropout      ‚îÇ      0 ‚îÇ train ‚îÇ [[1, 64, 15, ‚îÇ [[1, 64, 15, ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ    50], '?', ‚îÇ    50], '?'] ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ         '?'] ‚îÇ              ‚îÇ\n",
            "‚îÇ 14 ‚îÇ net.S_11  ‚îÇ Reshape      ‚îÇ      0 ‚îÇ train ‚îÇ [[1, 64, 15, ‚îÇ [[1, 960, 1, ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ    50], '?', ‚îÇ    50], '?'] ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ         '?'] ‚îÇ              ‚îÇ\n",
            "‚îÇ 15 ‚îÇ net.L_12  ‚îÇ TransposedS‚Ä¶ ‚îÇ  1.9 M ‚îÇ train ‚îÇ [[1, 960, 1, ‚îÇ [[1, 400, 1, ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ    50], '?', ‚îÇ    50], '?'] ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ         '?'] ‚îÇ              ‚îÇ\n",
            "‚îÇ 16 ‚îÇ net.Do_13 ‚îÇ Dropout      ‚îÇ      0 ‚îÇ train ‚îÇ [[1, 400, 1, ‚îÇ [[1, 400, 1, ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ    50], '?', ‚îÇ    50], '?'] ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ         '?'] ‚îÇ              ‚îÇ\n",
            "‚îÇ 17 ‚îÇ net.L_14  ‚îÇ TransposedS‚Ä¶ ‚îÇ  963 K ‚îÇ train ‚îÇ [[1, 400, 1, ‚îÇ [[1, 400, 1, ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ    50], '?', ‚îÇ    50], '?'] ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ         '?'] ‚îÇ              ‚îÇ\n",
            "‚îÇ 18 ‚îÇ net.Do_15 ‚îÇ Dropout      ‚îÇ      0 ‚îÇ train ‚îÇ [[1, 400, 1, ‚îÇ [[1, 400, 1, ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ    50], '?', ‚îÇ    50], '?'] ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ         '?'] ‚îÇ              ‚îÇ\n",
            "‚îÇ 19 ‚îÇ net.L_16  ‚îÇ TransposedS‚Ä¶ ‚îÇ  963 K ‚îÇ train ‚îÇ [[1, 400, 1, ‚îÇ [[1, 400, 1, ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ    50], '?', ‚îÇ    50], '?'] ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ         '?'] ‚îÇ              ‚îÇ\n",
            "‚îÇ 20 ‚îÇ net.Do_17 ‚îÇ Dropout      ‚îÇ      0 ‚îÇ train ‚îÇ [[1, 400, 1, ‚îÇ [[1, 400, 1, ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ    50], '?', ‚îÇ    50], '?'] ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ         '?'] ‚îÇ              ‚îÇ\n",
            "‚îÇ 21 ‚îÇ net.O_18  ‚îÇ LinSoftmax   ‚îÇ 24.1 K ‚îÇ train ‚îÇ [[1, 400, 1, ‚îÇ  [[1, 60, 1, ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ    50], '?', ‚îÇ    50], '?'] ‚îÇ\n",
            "‚îÇ    ‚îÇ           ‚îÇ              ‚îÇ        ‚îÇ       ‚îÇ         '?'] ‚îÇ              ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "Trainable params: 4.0 M                                                         \n",
            "Non-trainable params: 0                                                         \n",
            "Total params: 4.0 M                                                             \n",
            "Total estimated model params size (MB): 16                                      \n",
            "Modules in train mode: 40                                                       \n",
            "Modules in eval mode: 0                                                         \n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:516: You called `self.log('train_loss', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/lightning/pytorch/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 8. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/lightning/pytorch/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 6. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:516: You called `self.log('val_accuracy', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:516: You called `self.log('val_word_accuracy', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:516: You called `self.log('val_metric', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "\n",
            "stage 0/‚àû ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 0:02:11 ‚Ä¢     0.11it/s train_loss_s‚Ä¶ early_stoppi‚Ä¶\n",
            "                              0:00:00                512.347       0/6 0.88721  \n",
            "                                                     val_accuracy:              \n",
            "                                                     0.887                      \n",
            "                                                     val_word_acc‚Ä¶              \n",
            "                                                     0.388                      \n",
            "                                                     train_loss_e‚Ä¶              \n",
            "                                                     724.073                    \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2025449551.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m# Stream every line from ketos directly into the notebook output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import shlex\n",
        "import textwrap\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Try to infer PROJECT_ID and BASE_DIR if they are not already defined\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "if 'PROJECT_ID' not in globals():\n",
        "    if 'BASE_MODEL' in globals() and BASE_MODEL:\n",
        "        # Try to extract project ID from a path like:\n",
        "        # /content/drive/MyDrive/kraken_projects/0093/models/rec/0088-recognizer-02.mlmodel\n",
        "        parts = BASE_MODEL.split('/')\n",
        "        if \"kraken_projects\" in parts:\n",
        "            idx = parts.index(\"kraken_projects\")\n",
        "            if idx + 1 < len(parts):\n",
        "                PROJECT_ID = parts[idx + 1]\n",
        "            else:\n",
        "                PROJECT_ID = \"default_project\"\n",
        "        else:\n",
        "            PROJECT_ID = \"default_project\"\n",
        "    else:\n",
        "        # Fallback ‚Äì adjust if your project ID is different\n",
        "        PROJECT_ID = \"0093\"\n",
        "\n",
        "if 'BASE_DIR' not in globals():\n",
        "    BASE_DIR = f\"/content/drive/MyDrive/kraken_projects/{PROJECT_ID}\"\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Train/val lists ‚Äì use existing vars if defined, otherwise defaults\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "_TR = TRAIN_LIST if 'TRAIN_LIST' in globals() else \"/content/alto_staged/train_local.txt\"\n",
        "_VA = VAL_LIST   if 'VAL_LIST'   in globals() else \"/content/alto_staged/val_local.txt\"\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Output directory for this recognizer attempt\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "REC_MODELS_DIR = os.path.join(BASE_DIR, \"models\", \"rec\")\n",
        "os.makedirs(REC_MODELS_DIR, exist_ok=True)\n",
        "\n",
        "# ATTEMPT_ID normalization:\n",
        "#  - if missing  ‚Üí \"attempt_01\"\n",
        "#  - if int      ‚Üí \"attempt_XX\" (zero-padded)\n",
        "#  - if string   ‚Üí use as-is\n",
        "if 'ATTEMPT_ID' not in globals():\n",
        "    ATTEMPT_ID = \"attempt_01\"\n",
        "else:\n",
        "    if isinstance(ATTEMPT_ID, int):\n",
        "        ATTEMPT_ID = f\"attempt_{ATTEMPT_ID:02d}\"\n",
        "    else:\n",
        "        ATTEMPT_ID = str(ATTEMPT_ID)\n",
        "\n",
        "out_prefix = os.path.join(REC_MODELS_DIR, ATTEMPT_ID)\n",
        "\n",
        "print(\"üìÅ Project ID:     \", PROJECT_ID)\n",
        "print(\"üìÇ BASE_DIR:       \", BASE_DIR)\n",
        "print(\"üìÑ Train list:     \", _TR)\n",
        "print(\"üìÑ Val list:       \", _VA)\n",
        "print(\"üì¶ Output prefix:  \", out_prefix)\n",
        "print(\"üß† Base model:     \", BASE_MODEL if 'BASE_MODEL' in globals() else None)\n",
        "print()\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Build ketos train command\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "# Reasonable defaults if not defined earlier\n",
        "if 'LAG_EPOCHS' not in globals():\n",
        "    LAG_EPOCHS = 6\n",
        "if 'MIN_DELTA' not in globals():\n",
        "    MIN_DELTA = 0.0001\n",
        "if 'BATCH_SIZE' not in globals():\n",
        "    BATCH_SIZE = 8\n",
        "# LEARNING_RATE can stay None to use kraken's default\n",
        "\n",
        "cmd = [\n",
        "    \"ketos\", \"train\",\n",
        "    \"-o\", out_prefix,\n",
        "    \"-f\", \"alto\",\n",
        "    \"-t\", _TR,\n",
        "    \"-e\", _VA,\n",
        "    \"-q\", \"early\",\n",
        "    \"--lag\", str(int(LAG_EPOCHS)),\n",
        "    \"--min-delta\", str(float(MIN_DELTA)),\n",
        "    \"-B\", str(int(BATCH_SIZE)),\n",
        "    \"-F\", \"1\",  # report every epoch\n",
        "]\n",
        "\n",
        "# üîÅ IMPORTANT: allow codec resize when fine-tuning an existing model\n",
        "if 'BASE_MODEL' in globals() and BASE_MODEL:\n",
        "    cmd += [\"-i\", BASE_MODEL, \"--resize\", \"add\"]\n",
        "\n",
        "if 'LEARNING_RATE' in globals() and LEARNING_RATE is not None:\n",
        "    cmd += [\"-r\", str(LEARNING_RATE)]\n",
        "\n",
        "print(\"Running:\")\n",
        "print(textwrap.fill(\" \".join(shlex.quote(c) for c in cmd), width=120))\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Run training (line-by-line streaming)\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "proc = subprocess.Popen(\n",
        "    cmd,\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True,\n",
        "    bufsize=1,  # line-buffered\n",
        ")\n",
        "\n",
        "# Stream every line from ketos directly into the notebook output\n",
        "for line in proc.stdout:\n",
        "    print(line, end=\"\")\n",
        "\n",
        "proc.stdout.close()\n",
        "proc.wait()\n",
        "\n",
        "if proc.returncode != 0:\n",
        "    raise RuntimeError(\"Training did not complete cleanly; scroll up to see logs.\")\n",
        "else:\n",
        "    print(\"‚úÖ Training finished successfully.\")\n",
        "    print(\"‚úÖ Model(s) written with prefix:\", out_prefix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d8e8db5",
      "metadata": {
        "id": "8d8e8db5"
      },
      "source": [
        "## 9) Evaluate (CER/WER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0213fee2",
      "metadata": {
        "id": "0213fee2"
      },
      "outputs": [],
      "source": [
        "\n",
        "import shlex, subprocess\n",
        "\n",
        "cmd = [\"ketos\", \"test\", \"-f\", \"alto\", \"-m\", final_best, VAL_LIST]\n",
        "print(\"Running:\", \" \".join(shlex.quote(x) for x in cmd))\n",
        "res = subprocess.run(cmd, text=True)\n",
        "\n",
        "if res.returncode == 0:\n",
        "    print(\"‚úÖ Evaluation completed. See metrics above.\")\n",
        "else:\n",
        "    raise SystemExit(\"‚ùå Evaluation failed. Check the logs above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "501f4786",
      "metadata": {
        "id": "501f4786"
      },
      "source": [
        "\n",
        "### Notes\n",
        "- Change only `PROJECT_ID` in Project Settings; keep **everything else** under the project folder.\n",
        "- For each new attempt, adjust **ATTEMPT_ID**, **LEARNING_RATE**, and **BASE_SOURCE** in the **Training Controls** cell.\n",
        "- The best checkpoint for each attempt is copied to `attempt_XX.mlmodel` so you can chain attempts cleanly.\n",
        "- To warm-start a new manuscript from another one, keep **BASE_SOURCE = \"auto_other\"** for attempt 01 (or point to a model with `\"manual\"`).\n",
        "- For much faster training, switch to a **T4 GPU** in Colab and set `DEVICE = \"cuda\"`.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}