{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03fcf194",
   "metadata": {},
   "source": [
    "\n",
    "# Kraken + ALTO OCR ‚Äî Colab (Auto attempts, minimal edits)\n",
    "\n",
    "**You only change one thing ‚Üí `PROJECT_ID`** (the manuscript number).  \n",
    "The notebook will:\n",
    "- Install Kraken fast (uses a small pip cache on Drive).\n",
    "- Ask you to **upload a ZIP** (ALTO XML + images).\n",
    "- **Auto-build** train/val lists.\n",
    "- **Auto-detect attempts**:\n",
    "  - **Attempt 01** (no model yet for this manuscript): it will try to start **from the newest model of another manuscript** if available, otherwise start from scratch.\n",
    "  - **Attempt >01**: it will **resume from the best model** of the previous attempt and **lower the learning rate** (configurable).\n",
    "\n",
    "Run cells **top to bottom**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e8f68e",
   "metadata": {},
   "source": [
    "## 1) Connect Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb43159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import drive  # type: ignore\n",
    "drive.mount('/content/drive')\n",
    "print(\"‚úÖ Drive mounted at /content/drive\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dba53a3",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Project Settings (only edit `PROJECT_ID`)\n",
    "\n",
    "- `PROJECT_ID`: the manuscript number (e.g., `0093`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47a95a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title üîß Project Settings (edit only PROJECT_ID)\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ID = \"0093\"  #@param {type:\"string\"}\n",
    "\n",
    "ROOT_IN_DRIVE = \"/content/drive/MyDrive\"\n",
    "# Derived locations ‚Äî no need to edit\n",
    "MODELS_DIR = f\"{ROOT_IN_DRIVE}/kraken_models/{PROJECT_ID}/rec\"\n",
    "PIP_CACHE_DIR = f\"{ROOT_IN_DRIVE}/.pip-cache\"\n",
    "LISTS_DIR = \"/content/lists\"\n",
    "DATA_DIR = f\"/content/data/{PROJECT_ID}\"\n",
    "\n",
    "# Create folders\n",
    "for p in [MODELS_DIR, PIP_CACHE_DIR, LISTS_DIR, DATA_DIR]:\n",
    "    Path(p).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_LIST = f\"{LISTS_DIR}/train.txt\"\n",
    "VAL_LIST   = f\"{LISTS_DIR}/val.txt\"\n",
    "\n",
    "# Runtime defaults\n",
    "CPU_THREADS = 2\n",
    "DEVICE = \"cpu\"   # set to \"cuda\" if you enable T4 GPU in Colab\n",
    "\n",
    "print(\"‚úÖ Settings applied\")\n",
    "print(\"PROJECT_ID:\", PROJECT_ID)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"MODELS_DIR:\", MODELS_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05978a6",
   "metadata": {},
   "source": [
    "## 3) Install Kraken (fast, cached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef879387",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, subprocess, shlex\n",
    "\n",
    "os.environ[\"PIP_CACHE_DIR\"] = PIP_CACHE_DIR\n",
    "\n",
    "def is_importable(pkg: str) -> bool:\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "if is_importable(\"kraken\"):\n",
    "    import kraken\n",
    "    try:\n",
    "        import torch\n",
    "        torch_v = torch.__version__\n",
    "    except Exception:\n",
    "        torch_v = \"unknown\"\n",
    "    print(f\"‚úÖ Kraken available (version: {getattr(kraken, '__version__', 'unknown')}) | Torch: {torch_v}\")\n",
    "else:\n",
    "    print(\"‚è≥ Installing Kraken ...\")\n",
    "    subprocess.run(shlex.split(\"python -m pip -q install --upgrade pip\"), check=True)\n",
    "    subprocess.run(shlex.split(\"python -m pip -q install 'kraken[cairo]'\"), check=True)\n",
    "    import kraken, importlib\n",
    "    importlib.reload(kraken)\n",
    "    try:\n",
    "        import torch\n",
    "        torch_v = torch.__version__\n",
    "    except Exception:\n",
    "        torch_v = \"unknown\"\n",
    "    print(f\"‚úÖ Installed Kraken (version: {getattr(kraken, '__version__', 'unknown')}) | Torch: {torch_v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6e489f",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Upload your ALTO dataset (ZIP)\n",
    "- ZIP should include ALTO XMLs and their page images.\n",
    "- We extract to `DATA_DIR` and build train/val lists automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e1d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import files  # type: ignore\n",
    "import zipfile, os\n",
    "\n",
    "print(\"üì¶ Please select your ZIP...\")\n",
    "uploaded = files.upload()\n",
    "if not uploaded:\n",
    "    raise SystemExit(\"‚ùå No file uploaded.\")\n",
    "\n",
    "zip_name = next(iter(uploaded.keys()))\n",
    "zip_path = f\"/content/{zip_name}\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "    zf.extractall(DATA_DIR)\n",
    "\n",
    "print(f\"‚úÖ Extracted into: {DATA_DIR}\")\n",
    "!find \"$DATA_DIR\" -maxdepth 2 -type f | head -n 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223f4afe",
   "metadata": {},
   "source": [
    "## 5) Build train/val lists from ALTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284e500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "IMG_EXTS = {\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\"}\n",
    "\n",
    "def _strip_ns(tag: str) -> str:\n",
    "    return tag.split('}', 1)[1] if '}' in tag else tag\n",
    "\n",
    "def alto_image_from_xml(xml_path: Path) -> Optional[str]:\n",
    "    try:\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        for el in root.iter():\n",
    "            if _strip_ns(el.tag) == \"fileName\":\n",
    "                if el.text and el.text.strip():\n",
    "                    return el.text.strip()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def find_image_candidates(root: Path) -> dict:\n",
    "    images = {}\n",
    "    for p in root.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in IMG_EXTS:\n",
    "            images.setdefault(p.stem, str(p.resolve()))\n",
    "    return images\n",
    "\n",
    "def resolve_image_for_alto(xml_path: Path, data_root: Path, images_by_stem: dict) -> Optional[str]:\n",
    "    fn = alto_image_from_xml(xml_path)\n",
    "    if fn:\n",
    "        candidate = (xml_path.parent / fn)\n",
    "        if candidate.exists():\n",
    "            return str(candidate.resolve())\n",
    "        for p in data_root.rglob(Path(fn).name):\n",
    "            if p.is_file() and p.suffix.lower() in IMG_EXTS:\n",
    "                return str(p.resolve())\n",
    "    stem = xml_path.stem\n",
    "    return images_by_stem.get(stem)\n",
    "\n",
    "def find_pairs_alto_first(root: str) -> List[Tuple[str, str]]:\n",
    "    rootp = Path(root)\n",
    "    images_by_stem = find_image_candidates(rootp)\n",
    "    pairs: List[Tuple[str, str]] = []\n",
    "    for xml in rootp.rglob(\"*.xml\"):\n",
    "        try:\n",
    "            with open(xml, \"r\", encoding=\"utf-8\", errors=\"ignore\") as fh:\n",
    "                head = fh.read(4096)\n",
    "                if \"<alto\" not in head:\n",
    "                    continue\n",
    "        except Exception:\n",
    "            continue\n",
    "        img_path = resolve_image_for_alto(xml, rootp, images_by_stem)\n",
    "        if img_path:\n",
    "            pairs.append((img_path, str(xml.resolve())))\n",
    "    return pairs\n",
    "\n",
    "def write_list(pairs: List[Tuple[str, str]], out_path: str):\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for img, xml in pairs:\n",
    "            f.write(f\"{img}\\t{xml}\\n\")\n",
    "\n",
    "pairs = sorted(set(find_pairs_alto_first(DATA_DIR)))\n",
    "n = len(pairs)\n",
    "print(f\"Found {n} image+ALTO pairs.\")\n",
    "\n",
    "if n < 2:\n",
    "    raise SystemExit(f\"‚ùå Not enough samples in {DATA_DIR}. Found {n}. Check your ZIP structure.\")\n",
    "\n",
    "# 90/10 split\n",
    "from math import floor\n",
    "cut = max(1, int(n * 0.9))\n",
    "train_pairs, val_pairs = pairs[:cut], pairs[cut:]\n",
    "Path(LISTS_DIR).mkdir(parents=True, exist_ok=True)\n",
    "write_list(train_pairs, TRAIN_LIST)\n",
    "write_list(val_pairs,   VAL_LIST)\n",
    "print(f\"‚úÖ Wrote lists ‚Üí {TRAIN_LIST} ({len(train_pairs)}), {VAL_LIST} ({len(val_pairs)})\")\n",
    "\n",
    "print(\"\\nSample train lines:\")\n",
    "print(\"\\n\".join(open(TRAIN_LIST, encoding=\"utf-8\").read().splitlines()[:5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f592d9",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Auto-detect attempt and choose base model\n",
    "\n",
    "- If **no model yet** for this manuscript ‚áí **Attempt 01**.  \n",
    "  - We try to use the **newest model from another manuscript** as base.\n",
    "- If there **is** at least one model ‚áí next attempt number (e.g., 02, 03, ‚Ä¶), and we **load the previous attempt‚Äôs best** as base.\n",
    "- For attempts **>01**, we also set a **lower learning rate** automatically (you can change the values below).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2741deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, re, glob, time\n",
    "from pathlib import Path\n",
    "\n",
    "ALL_MODELS_ROOT = f\"{ROOT_IN_DRIVE}/kraken_models\"\n",
    "\n",
    "def list_attempt_models(models_dir: str):\n",
    "    return sorted(Path(models_dir).glob(\"attempt_*.mlmodel\"))\n",
    "\n",
    "def next_attempt_id(models_dir: str) -> int:\n",
    "    attempts = list_attempt_models(models_dir)\n",
    "    if not attempts:\n",
    "        return 1\n",
    "    # extract numeric suffix\n",
    "    nums = []\n",
    "    for p in attempts:\n",
    "        m = re.search(r\"attempt_(\\d+)\\.mlmodel$\", p.name)\n",
    "        if m:\n",
    "            nums.append(int(m.group(1)))\n",
    "    return (max(nums) + 1) if nums else 1\n",
    "\n",
    "def find_previous_attempt_model(models_dir: str, attempt_id: int) -> str or None:\n",
    "    prev_id = attempt_id - 1\n",
    "    if prev_id < 1:\n",
    "        return None\n",
    "    cand = Path(models_dir) / f\"attempt_{prev_id:02d}.mlmodel\"\n",
    "    return str(cand) if cand.exists() else None\n",
    "\n",
    "def newest_model_from_other_projects(root_dir: str, exclude_project: str) -> str or None:\n",
    "    pattern = str(Path(root_dir) / \"*\" / \"rec\" / \"*.mlmodel\")\n",
    "    # newest by mtime\n",
    "    newest = None\n",
    "    newest_mtime = -1\n",
    "    for p in glob.glob(pattern):\n",
    "        if f\"/{exclude_project}/\" in p or f\"\\\\{exclude_project}\\\\\" in p:\n",
    "            continue\n",
    "        try:\n",
    "            mtime = os.path.getmtime(p)\n",
    "            if mtime > newest_mtime:\n",
    "                newest_mtime = mtime\n",
    "                newest = p\n",
    "        except Exception:\n",
    "            pass\n",
    "    return newest\n",
    "\n",
    "ATTEMPT_ID = next_attempt_id(MODELS_DIR)\n",
    "OUT_MODEL = str(Path(MODELS_DIR) / f\"attempt_{ATTEMPT_ID:02d}.mlmodel\")\n",
    "\n",
    "# Decide base model\n",
    "BASE_MODEL = None\n",
    "if ATTEMPT_ID == 1:\n",
    "    BASE_MODEL = newest_model_from_other_projects(ALL_MODELS_ROOT, PROJECT_ID)\n",
    "    if BASE_MODEL:\n",
    "        print(f\"‚ÑπÔ∏è Attempt {ATTEMPT_ID:02d}: using cross-manuscript base model ‚Üí {BASE_MODEL}\")\n",
    "    else:\n",
    "        print(f\"‚ÑπÔ∏è Attempt {ATTEMPT_ID:02d}: no cross-manuscript base found. Training from scratch.\")\n",
    "else:\n",
    "    BASE_MODEL = find_previous_attempt_model(MODELS_DIR, ATTEMPT_ID)\n",
    "    if BASE_MODEL:\n",
    "        print(f\"‚ÑπÔ∏è Attempt {ATTEMPT_ID:02d}: resuming from previous attempt ‚Üí {BASE_MODEL}\")\n",
    "    else:\n",
    "        print(f\"‚ÑπÔ∏è Attempt {ATTEMPT_ID:02d}: previous attempt model not found; training from scratch.\")\n",
    "\n",
    "# Learning rate policy\n",
    "LR_FOR_ATTEMPT_1 = 1e-3     # used if we *explicitly* set LR for attempt 1 (we may omit)\n",
    "LR_FOR_LATER      = 1e-4     # smaller LR for attempts > 1\n",
    "\n",
    "# Decide LR\n",
    "AUTO_LR = None\n",
    "if ATTEMPT_ID > 1:\n",
    "    AUTO_LR = LR_FOR_LATER\n",
    "else:\n",
    "    # For attempt 1 we can omit LR (ketos default) or set LR_FOR_ATTEMPT_1\n",
    "    AUTO_LR = None  # keep None to use ketos default; set to LR_FOR_ATTEMPT_1 to enforce\n",
    "\n",
    "print(f\"ATTEMPT_ID: {ATTEMPT_ID:02d}\") \n",
    "print(f\"OUT_MODEL: {OUT_MODEL}\") \n",
    "print(f\"BASE_MODEL: {BASE_MODEL}\") \n",
    "print(f\"AUTO_LR: {AUTO_LR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faec75b",
   "metadata": {},
   "source": [
    "## 7) Train recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ee237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import shlex, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "cmd = [\n",
    "    \"ketos\",\"train\",\n",
    "    \"-o\", OUT_MODEL,\n",
    "    \"--workers\", str(int(CPU_THREADS)),\n",
    "    \"--device\", DEVICE,\n",
    "    \"-f\", \"alto\",\n",
    "    TRAIN_LIST, VAL_LIST\n",
    "]\n",
    "\n",
    "if BASE_MODEL:\n",
    "    cmd += [\"--load\", BASE_MODEL]\n",
    "\n",
    "if AUTO_LR is not None:\n",
    "    # Add an explicit LR only when we decided to change it\n",
    "    cmd += [\"--lr\", str(AUTO_LR)]\n",
    "\n",
    "print(\"Running:\", \" \".join(shlex.quote(x) for x in cmd))\n",
    "result = subprocess.run(cmd, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(f\"‚úÖ Training finished. Model at: {OUT_MODEL}\")\n",
    "else:\n",
    "    raise SystemExit(\"‚ùå Training failed. Check the logs above.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8393e2",
   "metadata": {},
   "source": [
    "## 8) Evaluate (CER/WER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140dbed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import shlex, subprocess\n",
    "\n",
    "cmd = [\"ketos\", \"test\", \"-f\", \"alto\", \"-m\", OUT_MODEL, VAL_LIST]\n",
    "print(\"Running:\", \" \".join(shlex.quote(x) for x in cmd))\n",
    "res = subprocess.run(cmd, text=True)\n",
    "\n",
    "if res.returncode == 0:\n",
    "    print(\"‚úÖ Evaluation completed. See metrics above.\")\n",
    "else:\n",
    "    raise SystemExit(\"‚ùå Evaluation failed. Check the logs above.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf583c42",
   "metadata": {},
   "source": [
    "\n",
    "## Notes\n",
    "\n",
    "- **Auto-detected base model for Attempt 01:** we pick the newest `.mlmodel` from any other manuscript in `MyDrive/kraken_models/*/rec`. If none is found, we start from scratch.\n",
    "- **Resume on later attempts:** we load the previous attempt‚Äôs `.mlmodel` automatically and (by default) **lower the LR** (`1e-4`). Adjust `LR_FOR_LATER` in the attempt cell if desired.\n",
    "- **Only edit `PROJECT_ID`:** all other paths derive from it.\n",
    "- **GPU:** enable T4 GPU in Colab (Runtime ‚Üí Change runtime type) and set `DEVICE = \"cuda\"` in the settings cell.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
