{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Kraken_ALTO_Colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498153.8082"
      },
      "source": [
        "\n",
        "# ðŸ“’ Kraken Training on Colab â€” **ALTO** Makefile-Style (msia compatible)\n",
        "\n",
        "This notebook is tailored for **ALTO exports** (eScriptorium-style). It lets you:\n",
        "- Upload one or more **ZIPs** from Finder (auto-extracted)\n",
        "- (Optional) add Google Drive folders\n",
        "- Train **segmentation** and **recognition** with **custom learning rates**\n",
        "- Evaluate recognition (CER/WER)\n",
        "- Package outputs and (optionally) upload to **msia.escriptorium.fr**\n",
        "\n",
        "> In Colab: **Runtime â†’ Change runtime type â†’ GPU** before running.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498153.808245"
      },
      "source": [
        "\n",
        "# 0) GPU check\n",
        "!nvidia-smi || true\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498153.808298"
      },
      "source": [
        "## 1) Install Kraken + deps (Python 3.12 safe)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498153.808326"
      },
      "source": [
        "\n",
        "import sys, subprocess\n",
        "def pip_install(*pkgs):\n",
        "    print(\"pip install\", \" \".join(pkgs))\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *pkgs])\n",
        "KR_PIN = \"kraken==5.3.0\"\n",
        "pip_install(KR_PIN, \"torch>=2.1,<3\", \"cairocffi\", \"opencv-python\", \"lxml\", \"h5py\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498153.808351"
      },
      "source": [
        "\n",
        "# Verify installs\n",
        "from importlib.metadata import version, PackageNotFoundError\n",
        "import torch, shutil, sys\n",
        "def pkg_ver(name):\n",
        "    try: return version(name)\n",
        "    except PackageNotFoundError: return \"not installed\"\n",
        "print(\"python:\", sys.version.split()[0])\n",
        "print(\"kraken:\", pkg_ver(\"kraken\"))\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"cuda available:\", torch.cuda.is_available())\n",
        "print(\"ketos on PATH:\", shutil.which(\"ketos\"))\n",
        "!ketos --version || true\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498153.808376"
      },
      "source": [
        "## 2) Config â€” ALTO fixed, roots, and split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498153.8084"
      },
      "source": [
        "\n",
        "# ======= CONFIG (ALTO) =======\n",
        "FORMAT = \"alto\"  # hard-coded for ALTO exports\n",
        "\n",
        "# Optional: add Drive roots if you also keep ALTO data on Drive\n",
        "DRIVE_ROOTS = [\n",
        "    # \"/content/drive/MyDrive/my_alto_export_folder\"\n",
        "]\n",
        "\n",
        "# Validation split fraction\n",
        "VAL_FRACTION = 0.10\n",
        "# =============================\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498153.808425"
      },
      "source": [
        "### (Optional) Mount Google Drive if you use DRIVE_ROOTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498153.808452"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498153.808475"
      },
      "source": [
        "## 3) Upload ALTO ZIP(s) from Finder â€” auto-extract & discover roots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498153.808498"
      },
      "source": [
        "\n",
        "import os, io, zipfile, re\n",
        "from google.colab import files\n",
        "\n",
        "LOCAL_BASE = \"/content/data_alto\"\n",
        "os.makedirs(LOCAL_BASE, exist_ok=True)\n",
        "\n",
        "print(\"Upload one or more ALTO export ZIPs from Finder. They will be extracted into\", LOCAL_BASE)\n",
        "uploaded = files.upload()\n",
        "\n",
        "EXTRACTED_ROOTS = []\n",
        "for name, data in uploaded.items():\n",
        "    save_path = os.path.join(LOCAL_BASE, name)\n",
        "    with open(save_path, \"wb\") as f:\n",
        "        f.write(data)\n",
        "    if name.lower().endswith(\".zip\"):\n",
        "        base = re.sub(r\"\\s*\\(\\d+\\)\\s*$\", \"\", os.path.splitext(name)[0])\n",
        "        target_dir = os.path.join(LOCAL_BASE, base)\n",
        "        os.makedirs(target_dir, exist_ok=True)\n",
        "        with zipfile.ZipFile(io.BytesIO(data)) as zf:\n",
        "            zf.extractall(target_dir)\n",
        "        os.remove(save_path)\n",
        "        EXTRACTED_ROOTS.append(target_dir)\n",
        "    else:\n",
        "        EXTRACTED_ROOTS.append(LOCAL_BASE)\n",
        "\n",
        "print(\"Extracted roots:\", EXTRACTED_ROOTS if EXTRACTED_ROOTS else [\"(none; you can still use DRIVE_ROOTS)\"])\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498153.808526"
      },
      "source": [
        "## 4) Build merged ALTO XML list (case-insensitive) + sanity checks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498153.808551"
      },
      "source": [
        "\n",
        "import os, glob, xml.etree.ElementTree as ET\n",
        "\n",
        "ROOTS = [p for p in (EXTRACTED_ROOTS + DRIVE_ROOTS) if p and os.path.exists(p)]\n",
        "assert ROOTS, \"No existing roots found. Upload a ZIP or set DRIVE_ROOTS.\"\n",
        "\n",
        "def find_alto_xmls(root):\n",
        "    xmls = glob.glob(os.path.join(root, \"**\", \"*.xml\"), recursive=True) +            glob.glob(os.path.join(root, \"**\", \"*.XML\"), recursive=True)\n",
        "    out = []\n",
        "    for xp in xmls:\n",
        "        try:\n",
        "            r = ET.parse(xp).getroot()\n",
        "            if isinstance(r.tag, str) and \"alto\" in r.tag.lower():\n",
        "                out.append(xp)\n",
        "        except ET.ParseError:\n",
        "            pass\n",
        "    return sorted(out)\n",
        "\n",
        "xmls = []\n",
        "for root in ROOTS:\n",
        "    found = find_alto_xmls(root)\n",
        "    print(f\"[ALTO] {len(found):>5} XMLs in {root}\")\n",
        "    xmls.extend(found)\n",
        "\n",
        "print(\"TOTAL ALTO XML files:\", len(xmls))\n",
        "assert len(xmls) >= 3, \"Need at least a few ALTO XML pages.\"\n",
        "\n",
        "# Heuristic image presence check (by filename stem match)\n",
        "import collections\n",
        "stems = collections.Counter(os.path.splitext(os.path.basename(p))[0] for p in xmls)\n",
        "img_exts = {\".jpg\",\".jpeg\",\".tif\",\".tiff\",\".png\",\".jp2\",\".bmp\"}\n",
        "img_candidates = []\n",
        "for root in ROOTS:\n",
        "    for ext in img_exts:\n",
        "        img_candidates += glob.glob(os.path.join(root, \"**\", f\"*{ext}\"), recursive=True)\n",
        "img_stems = set(os.path.splitext(os.path.basename(p))[0] for p in img_candidates)\n",
        "missing = [s for s in stems if s not in img_stems]\n",
        "print(\"Heuristic: ALTO page stems without matching image file:\", len(missing))\n",
        "print(\"First few missing stems:\", missing[:10])\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498153.80858"
      },
      "source": [
        "## 5) Create explicit train/val lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498153.808604"
      },
      "source": [
        "\n",
        "import random, pathlib\n",
        "random.seed(42)\n",
        "\n",
        "random.shuffle(xmls)\n",
        "n_val = max(1, int(len(xmls)*VAL_FRACTION))\n",
        "val_xmls = xmls[:n_val]\n",
        "train_xmls = xmls[n_val:]\n",
        "\n",
        "pathlib.Path(\"/content/lists\").mkdir(parents=True, exist_ok=True)\n",
        "open(\"/content/lists/train.txt\",\"w\").write(\"\\n\".join(train_xmls))\n",
        "open(\"/content/lists/val.txt\",\"w\").write(\"\\n\".join(val_xmls))\n",
        "\n",
        "len(train_xmls), len(val_xmls)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498153.808631"
      },
      "source": [
        "## 6) Hyperparameters (+ auto device)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498153.808654"
      },
      "source": [
        "\n",
        "# ======= EDIT ME (Hyperparameters) =======\n",
        "import torch\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "# Recognition\n",
        "REC_EPOCHS = 30\n",
        "REC_BATCH  = 8\n",
        "REC_OPTIM  = \"Adam\"   # \"Adam\" or \"SGD\"\n",
        "REC_LR     = 1e-4     # If your Kraken errors on --lr, use --lrate in the command cell\n",
        "REC_WD     = 1e-5     # weight decay\n",
        "\n",
        "# Segmentation\n",
        "SEG_EPOCHS = 20\n",
        "SEG_BATCH  = 2\n",
        "SEG_OPTIM  = \"Adam\"\n",
        "SEG_LR     = 5e-4\n",
        "# =========================================\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498153.80868"
      },
      "source": [
        "## 7) Target: `train_seg` â€” Segmentation training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498153.808702"
      },
      "source": [
        "\n",
        "# Create output dir\n",
        "!mkdir -p /content/models\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498153.808725"
      },
      "source": [
        "\n",
        "# ===== train_seg =====\n",
        "# To adjust learning rate, modify --lr (or --lrate if your Kraken is older).\n",
        "# To change epochs, modify --epochs.\n",
        "# To change batch-size, modify --batch-size.\n",
        "# To continue training from a prior segmentation model, add:\n",
        "#    --load-model /path/to/seg_base.mlmodel\n",
        "\n",
        "import shlex, os\n",
        "\n",
        "seg_cmd = f'''\n",
        "ketos segtrain -f {shlex.quote(FORMAT)} @/content/lists/train.txt \\\n",
        "  -o /content/models/seg \\\n",
        "  --device {shlex.quote(DEVICE)} \\\n",
        "  --epochs {SEG_EPOCHS} \\\n",
        "  --batch-size {SEG_BATCH} \\\n",
        "  --optimizer {shlex.quote(SEG_OPTIM)} --lr {SEG_LR} \\\n",
        "  --validation @/content/lists/val.txt\n",
        "'''\n",
        "print(seg_cmd)\n",
        "os.system(seg_cmd)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498153.808751"
      },
      "source": [
        "## 8) Target: `train_recog` â€” Recognition training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498153.808774"
      },
      "source": [
        "\n",
        "# ===== train_recog =====\n",
        "# To adjust learning rate, modify --lr (or --lrate if your Kraken is older).\n",
        "# To change epochs, modify --epochs.\n",
        "# To change batch-size, modify --batch-size.\n",
        "# To continue training from a prior recognizer, add:\n",
        "#    --load-model /path/to/rec_base.mlmodel\n",
        "\n",
        "import shlex, os\n",
        "\n",
        "rec_cmd = f'''\n",
        "ketos train -f {shlex.quote(FORMAT)} @/content/lists/train.txt \\\n",
        "  -o /content/models/rec \\\n",
        "  --device {shlex.quote(DEVICE)} \\\n",
        "  --epochs {REC_EPOCHS} \\\n",
        "  --batch-size {REC_BATCH} \\\n",
        "  --optimizer {shlex.quote(REC_OPTIM)} --lr {REC_LR} --weight-decay {REC_WD} \\\n",
        "  --validation @/content/lists/val.txt\n",
        "'''\n",
        "print(rec_cmd)\n",
        "os.system(rec_cmd)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498153.8088"
      },
      "source": [
        "## 9) Target: `eval` â€” Evaluate recognition (CER/WER)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498153.808823"
      },
      "source": [
        "\n",
        "# ===== eval =====\n",
        "# Evaluate the best recognition model on the held-out list:\n",
        "\n",
        "import shlex, os\n",
        "eval_cmd = f'''\n",
        "ketos test -f {shlex.quote(FORMAT)} /content/models/rec_best.mlmodel @/content/lists/val.txt\n",
        "'''\n",
        "print(eval_cmd)\n",
        "os.system(eval_cmd)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498153.808847"
      },
      "source": [
        "## 10) Package models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498153.808871"
      },
      "source": [
        "\n",
        "!cd /content/models && ls -lh && zip -r ../trained_models.zip . && cd /content\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761498153.808892"
      },
      "source": [
        "## 11) Optional: Upload to msia.escriptorium.fr via API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761498153.808916"
      },
      "source": [
        "\n",
        "# UI upload (My Models â†’ Upload) is simplest.\n",
        "# This cell shows how to POST a model programmatically if your instance supports it.\n",
        "\n",
        "MSIA_URL   = \"https://msia.escriptorium.fr\"\n",
        "API_TOKEN  = \"PASTE_YOUR_TOKEN_HERE\"   # keep secret; or leave blank and use UI upload\n",
        "MODEL_PATH = \"/content/models/rec_best.mlmodel\"   # or seg_best.mlmodel\n",
        "MODEL_NAME = \"rec_best\"\n",
        "\n",
        "if API_TOKEN and API_TOKEN != \"PASTE_YOUR_TOKEN_HERE\":\n",
        "    import requests\n",
        "    headers = {\"Authorization\": f\"Token {API_TOKEN}\"}\n",
        "    files = {\"file\": (MODEL_NAME + \".mlmodel\", open(MODEL_PATH, \"rb\"), \"application/octet-stream\")}\n",
        "    data  = {\"name\": MODEL_NAME}\n",
        "    resp = requests.post(f\"{MSIA_URL}/api/models/\", headers=headers, files=files, data=data)\n",
        "    print(\"Status:\", resp.status_code)\n",
        "    try:\n",
        "        print(resp.json())\n",
        "    except Exception:\n",
        "        print(resp.text[:800])\n",
        "else:\n",
        "    print(\"Skipping API upload. Use UI upload or paste a valid API token.\")\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ]
}