{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d2f9e28b",
      "metadata": {
        "id": "d2f9e28b"
      },
      "source": [
        "\n",
        "# Kraken + ALTO OCR â€” Colab (Perâ€‘Manuscript Projects, Bestâ€‘Model Saver)\n",
        "\n",
        "This notebook keeps **everything per manuscript** inside a dedicated Drive folder and trains **recognition** models on ALTO data.\n",
        "\n",
        "**What you get**\n",
        "- One-time **Project ID** â†’ creates `MyDrive/kraken_projects/<PROJECT_ID>/`\n",
        "- Upload ALTO **ZIP** â†’ auto-extracts to `data/`\n",
        "- ALTO-first pairing â†’ writes `train.txt` and `val.txt` to `lists/`\n",
        "- **Controls** for: attempt number, learning rate, base model (previous/manual/auto-other)\n",
        "- Training uses **`-t`/`-e`** (Kraken 3) and after training **copies the best checkpoint** to\n",
        "  `models/rec/attempt_XX.mlmodel`\n",
        "- CPU speed tweaks, lean Drive usage (small pip cache)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d85603cc",
      "metadata": {
        "id": "d85603cc"
      },
      "source": [
        "## 1) Connect Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d25c6397",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d25c6397",
        "outputId": "bafc34e0-4f16-44a9-bf27-c09f3d93633a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… Drive mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive  # type: ignore\n",
        "drive.mount('/content/drive')\n",
        "print(\"âœ… Drive mounted at /content/drive\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55530f22",
      "metadata": {
        "id": "55530f22"
      },
      "source": [
        "\n",
        "## 2) Project Settings (edit only `PROJECT_ID`)\n",
        "\n",
        "- `PROJECT_ID`: your manuscript ID (e.g., `0093`).  \n",
        "This cell creates the project folder tree on Drive:\n",
        "```\n",
        "MyDrive/kraken_projects/<PROJECT_ID>/\n",
        "â”œâ”€â”€ data/          # upload & extracted dataset (ALTO XML + images)\n",
        "â”œâ”€â”€ lists/         # train.txt, val.txt\n",
        "â””â”€â”€ models/\n",
        "    â””â”€â”€ rec/       # attempt_01.mlmodel, attempt_02.mlmodel, ...\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1e7c729d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e7c729d",
        "outputId": "f1d760f0-b586-4f56-977a-80d9a2d5a647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Project folders ready\n",
            "PROJECT_DIR: /content/drive/MyDrive/kraken_projects/0093\n",
            "DATA_DIR: /content/drive/MyDrive/kraken_projects/0093/data\n",
            "LISTS_DIR: /content/drive/MyDrive/kraken_projects/0093/lists\n",
            "REC_MODELS: /content/drive/MyDrive/kraken_projects/0093/models/rec\n",
            "CPU_THREADS: 2 | CORES: 2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#@title ğŸ”§ Project Settings\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "PROJECT_ID = \"0093\"  #@param {type:\"string\"}\n",
        "\n",
        "ROOT_IN_DRIVE = \"/content/drive/MyDrive\"\n",
        "PROJECTS_ROOT = f\"{ROOT_IN_DRIVE}/kraken_projects\"\n",
        "PROJECT_DIR   = f\"{PROJECTS_ROOT}/{PROJECT_ID}\"\n",
        "DATA_DIR      = f\"{PROJECT_DIR}/data\"\n",
        "LISTS_DIR     = f\"{PROJECT_DIR}/lists\"\n",
        "REC_MODELS    = f\"{PROJECT_DIR}/models/rec\"\n",
        "PIP_CACHE_DIR = f\"{ROOT_IN_DRIVE}/.pip-cache\"   # small cache only\n",
        "\n",
        "# Create the full project tree\n",
        "for p in [PROJECTS_ROOT, PROJECT_DIR, DATA_DIR, LISTS_DIR, REC_MODELS, PIP_CACHE_DIR]:\n",
        "    Path(p).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "TRAIN_LIST = f\"{LISTS_DIR}/train.txt\"\n",
        "VAL_LIST   = f\"{LISTS_DIR}/val.txt\"\n",
        "\n",
        "# CPU basics\n",
        "CORES = os.cpu_count() or 2\n",
        "CPU_THREADS = max(2, CORES - 1)\n",
        "DEVICE = \"cpu\"   # set \"cuda\" if you enable a T4 GPU in Colab\n",
        "\n",
        "print(\"âœ… Project folders ready\")\n",
        "print(\"PROJECT_DIR:\", PROJECT_DIR)\n",
        "print(\"DATA_DIR:\", DATA_DIR)\n",
        "print(\"LISTS_DIR:\", LISTS_DIR)\n",
        "print(\"REC_MODELS:\", REC_MODELS)\n",
        "print(\"CPU_THREADS:\", CPU_THREADS, \"| CORES:\", CORES)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76a2ad23",
      "metadata": {
        "id": "76a2ad23"
      },
      "source": [
        "## 3) CPU Speed Boost (threads & math libs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cf90e4c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf90e4c7",
        "outputId": "6a087176-2c8e-44d4-fa18-0c0c88966647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OMP_NUM_THREADS = 2\n",
            "MKL_NUM_THREADS = 2\n",
            "OPENBLAS_NUM_THREADS = 2\n",
            "NUMEXPR_NUM_THREADS = 2\n",
            "KMP_BLOCKTIME = 1\n",
            "KMP_AFFINITY = granularity=fine,compact,1,0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "os.environ[\"OMP_NUM_THREADS\"] = str(CPU_THREADS)\n",
        "os.environ[\"MKL_NUM_THREADS\"] = str(CPU_THREADS)\n",
        "os.environ[\"OPENBLAS_NUM_THREADS\"] = str(CPU_THREADS)\n",
        "os.environ[\"NUMEXPR_NUM_THREADS\"] = str(CPU_THREADS)\n",
        "os.environ[\"KMP_BLOCKTIME\"] = \"1\"\n",
        "os.environ[\"KMP_SETTINGS\"] = \"0\"\n",
        "os.environ[\"KMP_AFFINITY\"] = \"granularity=fine,compact,1,0\"\n",
        "\n",
        "for k in [\"OMP_NUM_THREADS\",\"MKL_NUM_THREADS\",\"OPENBLAS_NUM_THREADS\",\"NUMEXPR_NUM_THREADS\",\"KMP_BLOCKTIME\",\"KMP_AFFINITY\"]:\n",
        "    print(k, \"=\", os.environ.get(k))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55405fe0",
      "metadata": {
        "id": "55405fe0"
      },
      "source": [
        "## 4) Install Kraken (lean) + Pillowâ€‘SIMD (faster image I/O)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "70ea2704",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70ea2704",
        "outputId": "5ab0d90e-64c4-4bbd-a51b-72ee9d36a71c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â³ Installing Kraken (lean) ...\n",
            "âœ… Installed Kraken (version: unknown)\n",
            "â³ Switching to Pillow-SIMD for faster image ops...\n",
            "âœ… Pillow-SIMD installed\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Install Kraken (lean) + Pillow-SIMD (faster image IO)\n",
        "\n",
        "import os, subprocess, sys\n",
        "\n",
        "# Lean pip settings\n",
        "os.environ[\"PIP_CACHE_DIR\"] = PIP_CACHE_DIR\n",
        "os.environ[\"PIP_DISABLE_PIP_VERSION_CHECK\"] = \"1\"\n",
        "os.environ[\"PIP_NO_INPUT\"] = \"1\"\n",
        "\n",
        "def is_importable(pkg: str) -> bool:\n",
        "    try:\n",
        "        __import__(pkg)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# Install kraken only if missing\n",
        "if is_importable(\"kraken\"):\n",
        "    import kraken\n",
        "    print(f\"âœ… Kraken available (version: {getattr(kraken, '__version__', 'unknown')})\")\n",
        "else:\n",
        "    print(\"â³ Installing Kraken (lean) ...\")\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", \"--upgrade\", \"pip\"], check=True)\n",
        "    subprocess.run([\n",
        "        sys.executable, \"-m\", \"pip\", \"-q\", \"install\",\n",
        "        \"--prefer-binary\",\n",
        "        \"--upgrade-strategy\", \"only-if-needed\",\n",
        "        \"kraken[cairo]\"\n",
        "    ], check=True)\n",
        "    import kraken, importlib\n",
        "    importlib.reload(kraken)\n",
        "    print(f\"âœ… Installed Kraken (version: {getattr(kraken, '__version__', 'unknown')})\")\n",
        "\n",
        "# Switch to Pillow-SIMD for faster image decoding/resizing\n",
        "print(\"â³ Switching to Pillow-SIMD for faster image ops...\")\n",
        "# Don't fail the whole cell if Pillow isn't present yet\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"-q\", \"uninstall\", \"-y\", \"pillow\"], check=False)\n",
        "subprocess.run([\n",
        "    sys.executable, \"-m\", \"pip\", \"-q\", \"install\",\n",
        "    \"--prefer-binary\",\n",
        "    \"--upgrade-strategy\", \"only-if-needed\",\n",
        "    \"pillow-simd\"\n",
        "], check=True)\n",
        "print(\"âœ… Pillow-SIMD installed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d00b6c2",
      "metadata": {
        "id": "6d00b6c2"
      },
      "source": [
        "## 5) Upload your ALTO dataset (ZIP â†’ Drive project folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6e23c5b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "6e23c5b0",
        "outputId": "86147221-b844-41a0-94d2-a50f2d77a644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ Please select your ZIP (ALTO XML + images)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d9ee246b-3ddc-4942-aa38-1b30a8c373ee\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d9ee246b-3ddc-4942-aa38-1b30a8c373ee\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving export_doc5946_0093_alto_202510261625.zip to export_doc5946_0093_alto_202510261625.zip\n",
            "âœ… Extracted into: /content/drive/MyDrive/kraken_projects/0093/data\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/0020_mirrored.jpg\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/0020_mirrored.xml\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/0021_mirrored.jpg\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/0021_mirrored.xml\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/0022_mirrored.jpg\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/0022_mirrored.xml\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/0023_mirrored.jpg\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/0023_mirrored.xml\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/0024_mirrored.jpg\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/0024_mirrored.xml\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/0025_mirrored.jpg\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/0025_mirrored.xml\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/0026_mirrored.jpg\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/0026_mirrored.xml\n",
            "/content/drive/MyDrive/kraken_projects/0093/data/METS.xml\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import files  # type: ignore\n",
        "import zipfile, os\n",
        "\n",
        "print(\"ğŸ“¦ Please select your ZIP (ALTO XML + images)...\")\n",
        "uploaded = files.upload()\n",
        "if not uploaded:\n",
        "    raise SystemExit(\"âŒ No file uploaded.\")\n",
        "\n",
        "zip_name = next(iter(uploaded.keys()))\n",
        "zip_path = f\"/content/{zip_name}\"\n",
        "\n",
        "# Extract into the Drive project data folder\n",
        "with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "    zf.extractall(DATA_DIR)\n",
        "\n",
        "print(f\"âœ… Extracted into: {DATA_DIR}\")\n",
        "!find \"$DATA_DIR\" -maxdepth 2 -type f | head -n 20\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9127fd6c",
      "metadata": {
        "id": "9127fd6c"
      },
      "source": [
        "## 6) Build train/val lists from ALTO (in project folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e0bb1878",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0bb1878",
        "outputId": "1100e238-b472-4116-fbaa-697b70d95ec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7 ALTO XML files.\n",
            "âœ… Wrote lists:\n",
            "  - /content/drive/MyDrive/kraken_projects/0093/lists/train.txt: 6\n",
            "  - /content/drive/MyDrive/kraken_projects/0093/lists/val.txt:   1\n",
            "\n",
            "Sample from /content/drive/MyDrive/kraken_projects/0093/lists/train.txt:\n",
            "   /content/drive/MyDrive/kraken_projects/0093/data/0021_mirrored.xml\n",
            "   /content/drive/MyDrive/kraken_projects/0093/data/0023_mirrored.xml\n",
            "   /content/drive/MyDrive/kraken_projects/0093/data/0024_mirrored.xml\n",
            "   /content/drive/MyDrive/kraken_projects/0093/data/0022_mirrored.xml\n",
            "   /content/drive/MyDrive/kraken_projects/0093/data/0026_mirrored.xml\n",
            "\n",
            "Sample from /content/drive/MyDrive/kraken_projects/0093/lists/val.txt:\n",
            "   /content/drive/MyDrive/kraken_projects/0093/data/0025_mirrored.xml\n"
          ]
        }
      ],
      "source": [
        "# Build train/val lists for ALTO: ONE XML PATH PER LINE (no image paths)\n",
        "\n",
        "from pathlib import Path\n",
        "import xml.etree.ElementTree as ET\n",
        "import random, os\n",
        "\n",
        "random.seed(42)  # reproducible split\n",
        "\n",
        "DATA_DIR = DATA_DIR  # already defined\n",
        "LISTS_DIR = LISTS_DIR\n",
        "TRAIN_LIST = TRAIN_LIST\n",
        "VAL_LIST = VAL_LIST\n",
        "\n",
        "def is_alto_xml(p: Path) -> bool:\n",
        "    if p.suffix.lower() != \".xml\" or not p.is_file():\n",
        "        return False\n",
        "    try:\n",
        "        # quick scan first\n",
        "        with open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\") as fh:\n",
        "            head = fh.read(4096)\n",
        "            if \"<alto\" not in head:\n",
        "                return False\n",
        "        # light parse to be safe\n",
        "        ET.parse(p)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# Collect all ALTO XMLs under DATA_DIR\n",
        "xmls = [p for p in Path(DATA_DIR).rglob(\"*.xml\") if is_alto_xml(p)]\n",
        "xmls = sorted({x.resolve() for x in xmls})  # dedup + sort\n",
        "\n",
        "n = len(xmls)\n",
        "print(f\"Found {n} ALTO XML files.\")\n",
        "\n",
        "if n < 2:\n",
        "    raise SystemExit(f\"âŒ Not enough ALTO XMLs in {DATA_DIR}. Found {n}.\")\n",
        "\n",
        "# 90/10 split, shuffled\n",
        "random.shuffle(xmls)\n",
        "cut = max(1, int(n * 0.9))\n",
        "train_xmls, val_xmls = xmls[:cut], xmls[cut:]\n",
        "\n",
        "Path(LISTS_DIR).mkdir(parents=True, exist_ok=True)\n",
        "with open(TRAIN_LIST, \"w\", encoding=\"utf-8\") as f:\n",
        "    for x in train_xmls:\n",
        "        f.write(str(x) + \"\\n\")\n",
        "with open(VAL_LIST, \"w\", encoding=\"utf-8\") as f:\n",
        "    for x in val_xmls:\n",
        "        f.write(str(x) + \"\\n\")\n",
        "\n",
        "print(f\"âœ… Wrote lists:\")\n",
        "print(f\"  - {TRAIN_LIST}: {len(train_xmls)}\")\n",
        "print(f\"  - {VAL_LIST}:   {len(val_xmls)}\")\n",
        "\n",
        "# quick sanity check\n",
        "def show_sample(fp, k=5):\n",
        "    print(f\"\\nSample from {fp}:\")\n",
        "    with open(fp, encoding=\"utf-8\") as fh:\n",
        "        for i, line in enumerate(fh):\n",
        "            if i >= k: break\n",
        "            print(\"  \", line.strip())\n",
        "show_sample(TRAIN_LIST)\n",
        "show_sample(VAL_LIST)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76765693",
      "metadata": {
        "id": "76765693"
      },
      "source": [
        "\n",
        "## 7) Training Controls\n",
        "\n",
        "Set your **attempt number**, **learning rate** (or leave `None` for default), and how to choose the **base model**:\n",
        "- `auto_other`: pick the newest recognition model from **other** manuscripts/projects\n",
        "- `previous`: use the **previous attempt** in this manuscript\n",
        "- `manual`: use a **manual path** you specify\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "9b07f678",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b07f678",
        "outputId": "50390494-2de7-4bfa-b4d8-dea9cafc81cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ATTEMPT_ID: 19\n",
            "LEARNING_RATE: 0.0007\n",
            "BASE_SOURCE: choose\n",
            "BASE_ATTEMPT_TO_LOAD: 17\n"
          ]
        }
      ],
      "source": [
        "#@title ğŸ§­ Training Controls (choose or upload a base; no paths)\n",
        "ATTEMPT_ID = 19            #@param {type:\"number\"}\n",
        "LEARNING_RATE = 0.0007     #@param {type:\"number\"}  # set to 0 to use Kraken default\n",
        "BASE_SOURCE = \"choose\"     #@param [\"choose\", \"upload\"]\n",
        "BASE_ATTEMPT_TO_LOAD = 17  #@param {type:\"number\"}  # attempt to load if BASE_SOURCE=\"choose\"\n",
        "\n",
        "# Early stopping\n",
        "EARLY_STOP = \"early\"       #@param [\"early\", \"dumb\"]\n",
        "LAG_EPOCHS = 6             #@param {type:\"number\"}\n",
        "MIN_DELTA = 0.0001         #@param {type:\"number\"}\n",
        "\n",
        "# CPU perf\n",
        "import os\n",
        "BATCH_SIZE = min(32, max(8, (os.cpu_count() or 2) * 2))\n",
        "\n",
        "# Normalize LR (0 => None to use Kraken default)\n",
        "LEARNING_RATE = None if (LEARNING_RATE == 0) else LEARNING_RATE\n",
        "\n",
        "print(\"ATTEMPT_ID:\", ATTEMPT_ID)\n",
        "print(\"LEARNING_RATE:\", LEARNING_RATE)\n",
        "print(\"BASE_SOURCE:\", BASE_SOURCE)\n",
        "print(\"BASE_ATTEMPT_TO_LOAD:\", BASE_ATTEMPT_TO_LOAD)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ğŸ”— Resolve Base Model (STRICT: choose attempt or upload; no fallback)\n",
        "from pathlib import Path\n",
        "from google.colab import files  # type: ignore\n",
        "import shutil\n",
        "\n",
        "# Clear any stale value\n",
        "if 'BASE_MODEL' in globals():\n",
        "    del BASE_MODEL\n",
        "\n",
        "def list_available_attempts(rec_dir: str):\n",
        "    recp = Path(rec_dir)\n",
        "    found = sorted(p for p in recp.glob(\"attempt_*.mlmodel\"))\n",
        "    if not found:\n",
        "        print(\"â„¹ï¸ No attempts found yet in\", recp)\n",
        "        return\n",
        "    print(\"Available attempts in this manuscript:\")\n",
        "    for p in found:\n",
        "        print(\"  â€¢\", p.name)\n",
        "\n",
        "def upload_model_to_drive(dest_dir: str) -> str:\n",
        "    print(\"ğŸ“¤ Upload a .mlmodel file to use as baseâ€¦\")\n",
        "    up = files.upload()\n",
        "    if not up:\n",
        "        raise SystemExit(\"âŒ No file uploaded.\")\n",
        "    fname = next(iter(up.keys()))\n",
        "    src = f\"/content/{fname}\"\n",
        "    dest = str(Path(dest_dir) / Path(fname).name)\n",
        "    shutil.move(src, dest)\n",
        "    print(f\"âœ… Uploaded base to: {dest}\")\n",
        "    return dest\n",
        "\n",
        "BASE_MODEL = None\n",
        "\n",
        "if BASE_SOURCE == \"choose\":\n",
        "    chosen = Path(REC_MODELS) / f\"attempt_{int(BASE_ATTEMPT_TO_LOAD):02d}.mlmodel\"\n",
        "    if chosen.exists():\n",
        "        BASE_MODEL = str(chosen.resolve())\n",
        "        print(\"Base = chosen attempt:\", BASE_MODEL)\n",
        "    else:\n",
        "        print(f\"âŒ attempt_{int(BASE_ATTEMPT_TO_LOAD):02d}.mlmodel not found in {REC_MODELS}.\")\n",
        "        list_available_attempts(REC_MODELS)\n",
        "        raise SystemExit(\"Change BASE_ATTEMPT_TO_LOAD or switch to BASE_SOURCE='upload'.\")\n",
        "\n",
        "elif BASE_SOURCE == \"upload\":\n",
        "    BASE_MODEL = upload_model_to_drive(REC_MODELS)\n",
        "\n",
        "print(\"\\nâœ… BASE_MODEL resolved as:\", BASE_MODEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjKFQxjOYiX0",
        "outputId": "baa56c9c-0921-4974-b3f2-a7fb1f0571e8"
      },
      "id": "rjKFQxjOYiX0",
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base = chosen attempt: /content/drive/MyDrive/kraken_projects/0093/models/rec/attempt_17.mlmodel\n",
            "\n",
            "âœ… BASE_MODEL resolved as: /content/drive/MyDrive/kraken_projects/0093/models/rec/attempt_17.mlmodel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stage ALTO dataset locally (XMLs + images; rewrite <fileName>)\n",
        "copies XMLs and images and rewrites <fileName> to the local image basename"
      ],
      "metadata": {
        "id": "ZNRXaGczgaZI"
      },
      "id": "ZNRXaGczgaZI"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ğŸš€ Stage ALTO dataset locally (XMLs + images; rewrite <fileName>)\n",
        "# Copies XMLs referenced by TRAIN_LIST/VAL_LIST to /content/alto_staged/data,\n",
        "# copies their linked images next to them, and rewrites <fileName> in the\n",
        "# copied XML to the copied image basename. Produces LOCAL_TRAIN_LIST/LOCAL_VAL_LIST.\n",
        "\n",
        "from pathlib import Path\n",
        "import xml.etree.ElementTree as ET\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Inputs from earlier cells:\n",
        "# - TRAIN_LIST, VAL_LIST (XML-only lists)\n",
        "# Outputs from this cell:\n",
        "LOCAL_ROOT = Path(\"/content/alto_staged\")\n",
        "DATA_OUT   = LOCAL_ROOT / \"data\"\n",
        "LOCAL_TRAIN_LIST = str(LOCAL_ROOT / \"train_local.txt\")\n",
        "LOCAL_VAL_LIST   = str(LOCAL_ROOT / \"val_local.txt\")\n",
        "\n",
        "DATA_OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def _localname(tag: str) -> str:\n",
        "    \"\"\"Strip XML namespace from tag like {ns}tag â†’ tag.\"\"\"\n",
        "    return tag.split('}', 1)[1] if '}' in tag else tag\n",
        "\n",
        "def _find_alto_filename(root: ET.Element) -> str | None:\n",
        "    \"\"\"Return text of first <fileName> element, or None.\"\"\"\n",
        "    for el in root.iter():\n",
        "        if _localname(el.tag) == \"fileName\":\n",
        "            if el.text and el.text.strip():\n",
        "                return el.text.strip()\n",
        "    return None\n",
        "\n",
        "def _resolve_image(xml_path: Path, file_name_text: str) -> Path | None:\n",
        "    \"\"\"\n",
        "    Resolve the image path referenced by an ALTO <fileName>.\n",
        "    Try: (xml_dir / file_name), then search by basename around xml_dir.\n",
        "    \"\"\"\n",
        "    cand = (xml_path.parent / file_name_text)\n",
        "    if cand.exists():\n",
        "        return cand.resolve()\n",
        "    # Fallback: search by just the name (handles absolute or weird rel paths written into <fileName>)\n",
        "    base = Path(file_name_text).name\n",
        "    for p in xml_path.parent.rglob(base):\n",
        "        if p.exists() and p.is_file():\n",
        "            return p.resolve()\n",
        "    return None\n",
        "\n",
        "def _copy_with_rewrite(xml_in: Path, dst_dir: Path) -> Path | None:\n",
        "    \"\"\"\n",
        "    Copy xml_in and its linked image into dst_dir, rewrite <fileName> to point to copied image basename.\n",
        "    Return path to copied XML, or None if image canâ€™t be resolved.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # quick header sanity\n",
        "        with open(xml_in, \"r\", encoding=\"utf-8\", errors=\"ignore\") as fh:\n",
        "            if \"<alto\" not in fh.read(4096):\n",
        "                print(f\"âš ï¸ Not ALTO (skip): {xml_in}\")\n",
        "                return None\n",
        "\n",
        "        tree = ET.parse(xml_in)\n",
        "        root = tree.getroot()\n",
        "        fn_text = _find_alto_filename(root)\n",
        "        if not fn_text:\n",
        "            print(f\"âš ï¸ No <fileName> in: {xml_in}\")\n",
        "            return None\n",
        "\n",
        "        img_in = _resolve_image(xml_in, fn_text)\n",
        "        if not img_in:\n",
        "            print(f\"âš ï¸ Image not found for: {xml_in}  (<fileName>={fn_text})\")\n",
        "            return None\n",
        "\n",
        "        # Prepare destinations\n",
        "        dst_dir.mkdir(parents=True, exist_ok=True)\n",
        "        xml_out = dst_dir / xml_in.name\n",
        "        img_out = dst_dir / img_in.name\n",
        "\n",
        "        # Copy image (first) and xml\n",
        "        if not img_out.exists():\n",
        "            shutil.copy2(img_in, img_out)\n",
        "\n",
        "        # Rewrite <fileName> to local basename\n",
        "        for el in root.iter():\n",
        "            if _localname(el.tag) == \"fileName\":\n",
        "                el.text = img_out.name\n",
        "                break\n",
        "\n",
        "        tree.write(xml_out, encoding=\"utf-8\", xml_declaration=True)\n",
        "        return xml_out\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Failed on {xml_in}: {e}\")\n",
        "        return None\n",
        "\n",
        "def _collect_xmls(list_file: str) -> list[Path]:\n",
        "    out: list[Path] = []\n",
        "    with open(list_file, encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            p = Path(line.strip())\n",
        "            if p.suffix.lower() == \".xml\" and p.is_file():\n",
        "                out.append(p.resolve())\n",
        "            else:\n",
        "                # ignore empties/non-xmls silently\n",
        "                if line.strip():\n",
        "                    # print(f\"â„¹ï¸ Skipping non-XML or missing: {line.strip()}\")\n",
        "                    pass\n",
        "    return out\n",
        "\n",
        "def _stage_list(orig_list: str, new_list: str) -> int:\n",
        "    staged = []\n",
        "    xmls = _collect_xmls(orig_list)\n",
        "    for i, xml_in in enumerate(xmls, 1):\n",
        "        xml_out = _copy_with_rewrite(xml_in, DATA_OUT)\n",
        "        if xml_out:\n",
        "            staged.append(str(xml_out))\n",
        "        # Small progress ping every ~200 files\n",
        "        if i % 200 == 0:\n",
        "            print(f\"â€¦ staged {i}/{len(xmls)}\")\n",
        "    with open(new_list, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\\n\".join(staged) + \"\\n\")\n",
        "    print(f\"âœ… Staged {len(staged)} / {len(xmls)} â†’ {new_list}\")\n",
        "    return len(staged)\n",
        "\n",
        "# Run staging for train/val\n",
        "LOCAL_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "n_tr = _stage_list(TRAIN_LIST, LOCAL_TRAIN_LIST)\n",
        "n_va = _stage_list(VAL_LIST,   LOCAL_VAL_LIST)\n",
        "\n",
        "print(\"\\nLocal staged dataset:\")\n",
        "print(\"  Root:\", LOCAL_ROOT)\n",
        "print(\"  Data dir:\", DATA_OUT)\n",
        "print(\"  TRAIN (local):\", LOCAL_TRAIN_LIST, \" | entries:\", n_tr)\n",
        "print(\"  VAL   (local):\", LOCAL_VAL_LIST,   \" | entries:\", n_va)\n",
        "print(\"\\nğŸ‘‰ In your training cell set: _USE_LOCAL = True\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5frN8T4gWNd",
        "outputId": "25f0fc03-aaa2-462a-e489-4a5251b0372b"
      },
      "id": "h5frN8T4gWNd",
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Staged 6 / 6 â†’ /content/alto_staged/train_local.txt\n",
            "âœ… Staged 1 / 1 â†’ /content/alto_staged/val_local.txt\n",
            "\n",
            "Local staged dataset:\n",
            "  Root: /content/alto_staged\n",
            "  Data dir: /content/alto_staged/data\n",
            "  TRAIN (local): /content/alto_staged/train_local.txt  | entries: 6\n",
            "  VAL   (local): /content/alto_staged/val_local.txt  | entries: 1\n",
            "\n",
            "ğŸ‘‰ In your training cell set: _USE_LOCAL = True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e17be092",
      "metadata": {
        "id": "e17be092"
      },
      "source": [
        "\n",
        "## 8) Train recognition (best checkpoint â†’ `attempt_XX.mlmodel`)\n",
        "\n",
        "- Uses `-t` / `-e` with ALTO lists.\n",
        "- Selects base model per your control settings.\n",
        "- After training, copies `*_best.mlmodel` to `attempt_XX.mlmodel`.\n",
        "- Prints full logs if something fails.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "8b9e707d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8b9e707d",
        "outputId": "8f447928-8c7c-46ac-abc3-864f5bde9897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running: ketos train -o /content/drive/MyDrive/kraken_projects/0093/models/rec/attempt_19 -f alto -t /content/alto_staged/train_local.txt -e /content/alto_staged/val_local.txt -q early --lag 6 --min-delta 0.0001 -B 8 -F 1 -i /content/drive/MyDrive/kraken_projects/0093/models/rec/attempt_17.mlmodel -r 0.0007\n",
            "2025-10-28 00:56:27.546764: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761612987.572035   68916 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761612987.579199   68916 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761612987.597661   68916 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761612987.597704   68916 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761612987.597707   68916 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761612987.597710   68916 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-28 00:56:27.603357: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[10/28/25 00:56:33] WARNING  alphabet mismatch: chars in training   train.py:428\n",
            "                             set only: {'j', 'k', 'ÌŠ', 'á¹£', 'Ì°', 'ÌŒ',              \n",
            "                             'o', 'Å«'} (not included in accuracy                \n",
            "                             test during training)                              \n",
            "WARNING:kraken.lib.train:alphabet mismatch: chars in training set only: {'j', 'k', 'ÌŠ', 'á¹£', 'Ì°', 'ÌŒ', 'o', 'Å«'} (not included in accuracy test during training)\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
            "                    WARNING  Neural network has been trained on     train.py:639\n",
            "                             mode L images, training set contains               \n",
            "                             mode 1 data. Consider setting                      \n",
            "                             `force_binarization`                               \n",
            "WARNING:kraken.lib.train:Neural network has been trained on mode L images, training set contains mode 1 data. Consider setting `force_binarization`\n",
            "â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ    â”ƒ Name      â”ƒ Type         â”ƒ Params â”ƒ Mode  â”ƒ     In sizes â”ƒ    Out sizes â”ƒ\n",
            "â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ 0  â”‚ val_cer   â”‚ CharErrorRaâ€¦ â”‚      0 â”‚ train â”‚            ? â”‚            ? â”‚\n",
            "â”‚ 1  â”‚ val_wer   â”‚ WordErrorRaâ€¦ â”‚      0 â”‚ train â”‚            ? â”‚            ? â”‚\n",
            "â”‚ 2  â”‚ net       â”‚ MultiParamSâ€¦ â”‚  4.0 M â”‚ train â”‚ [[1, 1, 120, â”‚  [[1, 52, 1, â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚   400], '?'] â”‚    50], '?'] â”‚\n",
            "â”‚ 3  â”‚ net.C_0   â”‚ ActConv2D    â”‚  1.3 K â”‚ train â”‚ [[1, 1, 120, â”‚     [[1, 32, â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚   400], '?', â”‚   120, 400], â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚         '?'] â”‚         '?'] â”‚\n",
            "â”‚ 4  â”‚ net.Do_1  â”‚ Dropout      â”‚      0 â”‚ train â”‚     [[1, 32, â”‚     [[1, 32, â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚   120, 400], â”‚   120, 400], â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚    '?', '?'] â”‚         '?'] â”‚\n",
            "â”‚ 5  â”‚ net.Mp_2  â”‚ MaxPool      â”‚      0 â”‚ train â”‚     [[1, 32, â”‚ [[1, 32, 60, â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚   120, 400], â”‚   200], '?'] â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚    '?', '?'] â”‚              â”‚\n",
            "â”‚ 6  â”‚ net.C_3   â”‚ ActConv2D    â”‚ 40.0 K â”‚ train â”‚ [[1, 32, 60, â”‚ [[1, 32, 60, â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚   200], '?', â”‚   200], '?'] â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚         '?'] â”‚              â”‚\n",
            "â”‚ 7  â”‚ net.Do_4  â”‚ Dropout      â”‚      0 â”‚ train â”‚ [[1, 32, 60, â”‚ [[1, 32, 60, â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚   200], '?', â”‚   200], '?'] â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚         '?'] â”‚              â”‚\n",
            "â”‚ 8  â”‚ net.Mp_5  â”‚ MaxPool      â”‚      0 â”‚ train â”‚ [[1, 32, 60, â”‚ [[1, 32, 30, â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚   200], '?', â”‚   100], '?'] â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚         '?'] â”‚              â”‚\n",
            "â”‚ 9  â”‚ net.C_6   â”‚ ActConv2D    â”‚ 55.4 K â”‚ train â”‚ [[1, 32, 30, â”‚ [[1, 64, 30, â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚   100], '?', â”‚   100], '?'] â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚         '?'] â”‚              â”‚\n",
            "â”‚ 10 â”‚ net.Do_7  â”‚ Dropout      â”‚      0 â”‚ train â”‚ [[1, 64, 30, â”‚ [[1, 64, 30, â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚   100], '?', â”‚   100], '?'] â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚         '?'] â”‚              â”‚\n",
            "â”‚ 11 â”‚ net.Mp_8  â”‚ MaxPool      â”‚      0 â”‚ train â”‚ [[1, 64, 30, â”‚ [[1, 64, 15, â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚   100], '?', â”‚    50], '?'] â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚         '?'] â”‚              â”‚\n",
            "â”‚ 12 â”‚ net.C_9   â”‚ ActConv2D    â”‚  110 K â”‚ train â”‚ [[1, 64, 15, â”‚ [[1, 64, 15, â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚    50], '?', â”‚    50], '?'] â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚         '?'] â”‚              â”‚\n",
            "â”‚ 13 â”‚ net.Do_10 â”‚ Dropout      â”‚      0 â”‚ train â”‚ [[1, 64, 15, â”‚ [[1, 64, 15, â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚    50], '?', â”‚    50], '?'] â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚         '?'] â”‚              â”‚\n",
            "â”‚ 14 â”‚ net.S_11  â”‚ Reshape      â”‚      0 â”‚ train â”‚ [[1, 64, 15, â”‚ [[1, 960, 1, â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚    50], '?', â”‚    50], '?'] â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚         '?'] â”‚              â”‚\n",
            "â”‚ 15 â”‚ net.L_12  â”‚ TransposedSâ€¦ â”‚  1.9 M â”‚ train â”‚ [[1, 960, 1, â”‚ [[1, 400, 1, â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚    50], '?', â”‚    50], '?'] â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚         '?'] â”‚              â”‚\n",
            "â”‚ 16 â”‚ net.Do_13 â”‚ Dropout      â”‚      0 â”‚ train â”‚ [[1, 400, 1, â”‚ [[1, 400, 1, â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚    50], '?', â”‚    50], '?'] â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚         '?'] â”‚              â”‚\n",
            "â”‚ 17 â”‚ net.L_14  â”‚ TransposedSâ€¦ â”‚  963 K â”‚ train â”‚ [[1, 400, 1, â”‚ [[1, 400, 1, â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚    50], '?', â”‚    50], '?'] â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚         '?'] â”‚              â”‚\n",
            "â”‚ 18 â”‚ net.Do_15 â”‚ Dropout      â”‚      0 â”‚ train â”‚ [[1, 400, 1, â”‚ [[1, 400, 1, â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚    50], '?', â”‚    50], '?'] â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚         '?'] â”‚              â”‚\n",
            "â”‚ 19 â”‚ net.L_16  â”‚ TransposedSâ€¦ â”‚  963 K â”‚ train â”‚ [[1, 400, 1, â”‚ [[1, 400, 1, â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚    50], '?', â”‚    50], '?'] â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚         '?'] â”‚              â”‚\n",
            "â”‚ 20 â”‚ net.Do_17 â”‚ Dropout      â”‚      0 â”‚ train â”‚ [[1, 400, 1, â”‚ [[1, 400, 1, â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚    50], '?', â”‚    50], '?'] â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚         '?'] â”‚              â”‚\n",
            "â”‚ 21 â”‚ net.O_18  â”‚ LinSoftmax   â”‚ 20.9 K â”‚ train â”‚ [[1, 400, 1, â”‚  [[1, 52, 1, â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚    50], '?', â”‚    50], '?'] â”‚\n",
            "â”‚    â”‚           â”‚              â”‚        â”‚       â”‚         '?'] â”‚              â”‚\n",
            "â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "Trainable params: 4.0 M                                                         \n",
            "Non-trainable params: 0                                                         \n",
            "Total params: 4.0 M                                                             \n",
            "Total estimated model params size (MB): 16                                      \n",
            "Modules in train mode: 40                                                       \n",
            "Modules in eval mode: 0                                                         \n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:516: You called `self.log('train_loss', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/lightning/pytorch/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 8. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/lightning/pytorch/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 6. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:516: You called `self.log('val_accuracy', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:516: You called `self.log('val_word_accuracy', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:516: You called `self.log('val_metric', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "\n",
            "stage 0/âˆ â”â”â”â”â”â”â”â”â”â”â”â”â” 13/13 0:02:10 â€¢     0.11it/s train_loss_sâ€¦ early_stoppiâ€¦\n",
            "                              0:00:00                14.742        0/6 0.91077  \n",
            "                                                     val_accuracy:              \n",
            "                                                     0.911                      \n",
            "                                                     val_word_accâ€¦              \n",
            "                                                     0.565                      \n",
            "                                                     train_loss_eâ€¦              \n",
            "                                                     103.283                    \n",
            "âœ… Saved best checkpoint as: /content/drive/MyDrive/kraken_projects/0093/models/rec/attempt_19.mlmodel\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3288206148.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Print as-is; Kraken emits progress/epoch lines here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# === Recognition Training (streaming logs, keep BEST as attempt_XX.mlmodel) ===\n",
        "# Requirements from earlier cells:\n",
        "# - PROJECT_ID, REC_MODELS, ATTEMPT_ID, LEARNING_RATE, LAG_EPOCHS, MIN_DELTA, BATCH_SIZE\n",
        "# - TRAIN_LIST / VAL_LIST (or LOCAL_TRAIN_LIST / LOCAL_VAL_LIST if you staged)\n",
        "# - BASE_MODEL (resolved by the resolver cell; may be None)\n",
        "\n",
        "import os, shlex, subprocess, sys, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# If you ran the \"staging\" step, set these to the staged lists; otherwise keep originals\n",
        "_USE_LOCAL = True  # set True if you built LOCAL_* lists\n",
        "_TR = LOCAL_TRAIN_LIST if _USE_LOCAL else TRAIN_LIST\n",
        "_VA = LOCAL_VAL_LIST   if _USE_LOCAL else VAL_LIST\n",
        "\n",
        "out_prefix = str(Path(REC_MODELS) / f\"attempt_{ATTEMPT_ID:02d}\")\n",
        "final_best = str(Path(REC_MODELS) / f\"attempt_{ATTEMPT_ID:02d}.mlmodel\")\n",
        "\n",
        "# Build the ketos command using the flags your --help supports\n",
        "cmd = [\n",
        "    \"ketos\", \"train\",\n",
        "    \"-o\", out_prefix,\n",
        "    \"-f\", \"alto\",\n",
        "    \"-t\", _TR,\n",
        "    \"-e\", _VA,\n",
        "    \"-q\", \"early\",\n",
        "    \"--lag\", str(int(LAG_EPOCHS)),\n",
        "    \"--min-delta\", str(float(MIN_DELTA)),\n",
        "    \"-B\", str(int(BATCH_SIZE)),\n",
        "    \"-F\", \"1\",  # report every epoch\n",
        "]\n",
        "if 'BASE_MODEL' in globals() and BASE_MODEL:\n",
        "    cmd += [\"-i\", BASE_MODEL]\n",
        "if LEARNING_RATE is not None:\n",
        "    cmd += [\"-r\", str(LEARNING_RATE)]\n",
        "\n",
        "print(\"Running:\", \" \".join(shlex.quote(x) for x in cmd))\n",
        "\n",
        "# Ensure unbuffered Python output from ketos so logs appear immediately\n",
        "env = os.environ.copy()\n",
        "env[\"PYTHONUNBUFFERED\"] = \"1\"\n",
        "\n",
        "# Stream logs live (no buffering). bufsize=1 + text=True for line-buffered output.\n",
        "proc = subprocess.Popen(\n",
        "    cmd,\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True,\n",
        "    bufsize=1,\n",
        "    env=env,\n",
        ")\n",
        "\n",
        "try:\n",
        "    for line in proc.stdout:\n",
        "        # Print as-is; Kraken emits progress/epoch lines here\n",
        "        print(line, end=\"\")\n",
        "    proc.wait()\n",
        "    print(\"\\nReturn code:\", proc.returncode)\n",
        "finally:\n",
        "    # Keep only the best checkpoint as attempt_XX.mlmodel\n",
        "    def keep_best_only():\n",
        "        candidates = [\n",
        "            f\"{out_prefix}_best.mlmodel\",  # preferred\n",
        "            f\"{out_prefix}.mlmodel\",       # fallback\n",
        "        ]\n",
        "        best_src = next((c for c in candidates if Path(c).exists()), None)\n",
        "        if not best_src:\n",
        "            matches = sorted(Path(REC_MODELS).glob(f\"{Path(out_prefix).name}*.mlmodel\"))\n",
        "            best_src = str(matches[-1]) if matches else None\n",
        "        if not best_src:\n",
        "            print(f\"âŒ No trained model found for prefix {out_prefix}\")\n",
        "            return\n",
        "        shutil.copy2(best_src, final_best)\n",
        "        print(f\"âœ… Saved best checkpoint as: {final_best}\")\n",
        "\n",
        "    keep_best_only()\n",
        "\n",
        "if proc.returncode != 0:\n",
        "    raise RuntimeError(\"Training did not complete cleanly; check logs above.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d8e8db5",
      "metadata": {
        "id": "8d8e8db5"
      },
      "source": [
        "## 9) Evaluate (CER/WER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0213fee2",
      "metadata": {
        "id": "0213fee2"
      },
      "outputs": [],
      "source": [
        "\n",
        "import shlex, subprocess\n",
        "\n",
        "cmd = [\"ketos\", \"test\", \"-f\", \"alto\", \"-m\", final_best, VAL_LIST]\n",
        "print(\"Running:\", \" \".join(shlex.quote(x) for x in cmd))\n",
        "res = subprocess.run(cmd, text=True)\n",
        "\n",
        "if res.returncode == 0:\n",
        "    print(\"âœ… Evaluation completed. See metrics above.\")\n",
        "else:\n",
        "    raise SystemExit(\"âŒ Evaluation failed. Check the logs above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "501f4786",
      "metadata": {
        "id": "501f4786"
      },
      "source": [
        "\n",
        "### Notes\n",
        "- Change only `PROJECT_ID` in Project Settings; keep **everything else** under the project folder.\n",
        "- For each new attempt, adjust **ATTEMPT_ID**, **LEARNING_RATE**, and **BASE_SOURCE** in the **Training Controls** cell.\n",
        "- The best checkpoint for each attempt is copied to `attempt_XX.mlmodel` so you can chain attempts cleanly.\n",
        "- To warm-start a new manuscript from another one, keep **BASE_SOURCE = \"auto_other\"** for attempt 01 (or point to a model with `\"manual\"`).\n",
        "- For much faster training, switch to a **T4 GPU** in Colab and set `DEVICE = \"cuda\"`.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}