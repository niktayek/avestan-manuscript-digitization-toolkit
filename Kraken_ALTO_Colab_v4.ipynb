{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Kraken_ALTO_Colab_v4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761499585.3528943"
      },
      "source": [
        "\n",
        "# ðŸ“’ Kraken Training â€” **ALTO-only** (Colab, live logs, smoke test included)\n",
        "\n",
        "**What you get**\n",
        "- Upload ALTO export ZIP(s) â†’ auto-extracted\n",
        "- Auto-discover ALTO XMLs (case-insensitive)\n",
        "- **Smoke test** (1 epoch) to verify wiring\n",
        "- Full **recognition** and **segmentation** training with **live logs**\n",
        "- Evaluation + packaging\n",
        "- Optional upload to **msia.escriptorium.fr**\n",
        "\n",
        "> In Colab: **Runtime â†’ Change runtime type â†’ GPU** (recommended).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761499585.3529313"
      },
      "source": [
        "\n",
        "# 0) GPU check\n",
        "!nvidia-smi || true\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761499585.3529572"
      },
      "source": [
        "## 1) Install Kraken (Py 3.12 safe) + deps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761499585.3529813"
      },
      "source": [
        "\n",
        "import sys, subprocess\n",
        "def pip_install(*pkgs):\n",
        "    print(\"pip install\", \" \".join(pkgs))\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *pkgs])\n",
        "\n",
        "# Colab-friendly pin\n",
        "KR_PIN = \"kraken==5.3.0\"\n",
        "pip_install(KR_PIN, \"torch>=2.1,<3\", \"cairocffi\", \"opencv-python\", \"lxml\", \"h5py\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761499585.3530066"
      },
      "source": [
        "\n",
        "from importlib.metadata import version, PackageNotFoundError\n",
        "import torch, shutil, sys\n",
        "def pkg_ver(name):\n",
        "    try: return version(name)\n",
        "    except PackageNotFoundError: return \"not installed\"\n",
        "print(\"python:\", sys.version.split()[0])\n",
        "print(\"kraken:\", pkg_ver(\"kraken\"))\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"cuda available:\", torch.cuda.is_available())\n",
        "print(\"ketos path:\", shutil.which(\"ketos\"))\n",
        "!ketos --version || true\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761499585.35304"
      },
      "source": [
        "## 2) Config â€” ALTO fixed, validation split, optional Drive roots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761499585.3530777"
      },
      "source": [
        "\n",
        "# ======= CONFIG (ALTO) =======\n",
        "FORMAT = \"alto\"     # hard-coded\n",
        "VAL_FRACTION = 0.10 # change if you want\n",
        "# Optional: add Drive roots if you also keep ALTO data on Drive\n",
        "DRIVE_ROOTS = [\n",
        "    # \"/content/drive/MyDrive/my_alto_export_folder\"\n",
        "]\n",
        "# =============================\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761499585.3531036"
      },
      "source": [
        "### (Optional) Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761499585.3531272"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761499585.3531506"
      },
      "source": [
        "## 3) Upload ALTO ZIP(s) â€” auto-extract and discover roots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761499585.3531744"
      },
      "source": [
        "\n",
        "import os, io, zipfile, re\n",
        "from google.colab import files\n",
        "\n",
        "LOCAL_BASE = \"/content/data_alto\"\n",
        "os.makedirs(LOCAL_BASE, exist_ok=True)\n",
        "\n",
        "print(\"Upload ALTO export ZIP(s). They will be extracted into\", LOCAL_BASE)\n",
        "uploaded = files.upload()\n",
        "\n",
        "EXTRACTED_ROOTS = []\n",
        "for name, data in uploaded.items():\n",
        "    path = os.path.join(LOCAL_BASE, name)\n",
        "    with open(path, \"wb\") as f: f.write(data)\n",
        "    if name.lower().endswith(\".zip\"):\n",
        "        # strip any \"(1)\" suffix and .zip\n",
        "        base = re.sub(r\"\\s*\\(\\d+\\)\\s*$\", \"\", os.path.splitext(name)[0])\n",
        "        target = os.path.join(LOCAL_BASE, base)\n",
        "        os.makedirs(target, exist_ok=True)\n",
        "        with zipfile.ZipFile(io.BytesIO(data)) as zf:\n",
        "            zf.extractall(target)\n",
        "        os.remove(path)\n",
        "        EXTRACTED_ROOTS.append(target)\n",
        "    else:\n",
        "        EXTRACTED_ROOTS.append(LOCAL_BASE)\n",
        "\n",
        "print(\"Extracted roots:\")\n",
        "for r in EXTRACTED_ROOTS: print(\" -\", r)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761499585.3532019"
      },
      "source": [
        "## 4) Build merged ALTO XML list + quick sanity checks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761499585.3532255"
      },
      "source": [
        "\n",
        "import os, glob, xml.etree.ElementTree as ET\n",
        "\n",
        "ROOTS = [p for p in (EXTRACTED_ROOTS + DRIVE_ROOTS) if p and os.path.exists(p)]\n",
        "assert ROOTS, \"No roots found. Upload a ZIP or set DRIVE_ROOTS and re-run.\"\n",
        "\n",
        "def find_alto_xmls(root):\n",
        "    xmls = glob.glob(os.path.join(root, \"**\", \"*.xml\"), recursive=True) +            glob.glob(os.path.join(root, \"**\", \"*.XML\"), recursive=True)\n",
        "    out = []\n",
        "    for xp in xmls:\n",
        "        try:\n",
        "            r = ET.parse(xp).getroot()\n",
        "            if isinstance(r.tag, str) and \"alto\" in r.tag.lower():\n",
        "                out.append(xp)\n",
        "        except ET.ParseError:\n",
        "            pass\n",
        "    return sorted(out)\n",
        "\n",
        "xmls = []\n",
        "for root in ROOTS:\n",
        "    found = find_alto_xmls(root)\n",
        "    print(f\"[ALTO] {len(found):>5} XMLs in {root}\")\n",
        "    xmls.extend(found)\n",
        "\n",
        "print(\"TOTAL ALTO XML files:\", len(xmls))\n",
        "assert len(xmls) >= 3, \"Need at least a few ALTO XML pages.\"\n",
        "\n",
        "# Show a few\n",
        "for p in xmls[:5]: print(\" â€¢\", p)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761499585.3532658"
      },
      "source": [
        "## 5) Create train/val lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761499585.3532927"
      },
      "source": [
        "\n",
        "import random, pathlib\n",
        "random.seed(42)\n",
        "\n",
        "random.shuffle(xmls)\n",
        "n_val = max(1, int(len(xmls)*VAL_FRACTION))\n",
        "val_xmls = xmls[:n_val]\n",
        "train_xmls = xmls[n_val:]\n",
        "\n",
        "pathlib.Path(\"/content/lists\").mkdir(parents=True, exist_ok=True)\n",
        "open(\"/content/lists/train.txt\",\"w\").write(\"\\n\".join(train_xmls))\n",
        "open(\"/content/lists/val.txt\",\"w\").write(\"\\n\".join(val_xmls))\n",
        "\n",
        "print(\"Train pages:\", len(train_xmls), \"| Val pages:\", len(val_xmls))\n",
        "print(\"First train:\", train_xmls[:2])\n",
        "print(\"First val:\", val_xmls[:2])\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761499585.3533196"
      },
      "source": [
        "## 6) Hyperparameters (+ auto device) â€” change LR here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761499585.353343"
      },
      "source": [
        "\n",
        "# ======= EDIT ME (Hyperparameters) =======\n",
        "import torch, os, shutil\n",
        "\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n",
        "KETOS = shutil.which(\"ketos\") or \"ketos\"\n",
        "print(\"ketos path:\", KETOS)\n",
        "\n",
        "# Recognition\n",
        "REC_EPOCHS = 30\n",
        "REC_BATCH  = 8\n",
        "REC_OPTIM  = \"Adam\"    # or \"SGD\"\n",
        "REC_LR     = 0.0001    # <-- change learning rate here\n",
        "REC_WD     = 1e-5\n",
        "\n",
        "# Segmentation\n",
        "SEG_EPOCHS = 20\n",
        "SEG_BATCH  = 2\n",
        "SEG_OPTIM  = \"Adam\"\n",
        "SEG_LR     = 0.0005    # <-- change learning rate here\n",
        "# =========================================\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761499585.353369"
      },
      "source": [
        "### (Optional) Peek at lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761499585.3534057"
      },
      "source": [
        "\n",
        "!sed -n '1,5p' /content/lists/train.txt\n",
        "!sed -n '1,5p' /content/lists/val.txt\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761499585.353446"
      },
      "source": [
        "## 7) ðŸ”Ž Smoke test â€” recognition (1 epoch, small batch, live logs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761499585.353472"
      },
      "source": [
        "\n",
        "%%bash\n",
        "set -euo pipefail\n",
        "which ketos || true\n",
        "stdbuf -oL -eL ketos train -v   -f alto @/content/lists/train.txt   -o /content/models/rec_smoke   --device cpu   --epochs 1   --batch-size 2   --optimizer Adam --lr 0.0001 --weight-decay 1e-5   --validation @/content/lists/val.txt\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761499585.3535097"
      },
      "source": [
        "## 8) â–¶ï¸ Recognition â€” full training (live logs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761499585.3535337"
      },
      "source": [
        "\n",
        "%%bash\n",
        "set -euo pipefail\n",
        "which ketos\n",
        "stdbuf -oL -eL ketos train -v   -f alto @/content/lists/train.txt   -o /content/models/rec   --device ${DEVICE:-cpu}   --epochs ${REC_EPOCHS:-30}   --batch-size ${REC_BATCH:-8}   --optimizer ${REC_OPTIM:-Adam} --lr ${REC_LR:-0.0001} --weight-decay ${REC_WD:-1e-5}   --validation @/content/lists/val.txt\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761499585.3535583"
      },
      "source": [
        "## 9) â–¶ï¸ Segmentation â€” full training (live logs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761499585.3535929"
      },
      "source": [
        "\n",
        "%%bash\n",
        "set -euo pipefail\n",
        "which ketos\n",
        "stdbuf -oL -eL ketos segtrain -v   -f alto @/content/lists/train.txt   -o /content/models/seg   --device ${DEVICE:-cpu}   --epochs ${SEG_EPOCHS:-20}   --batch-size ${SEG_BATCH:-2}   --optimizer ${SEG_OPTIM:-Adam} --lr ${SEG_LR:-0.0005}   --validation @/content/lists/val.txt\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761499585.353626"
      },
      "source": [
        "## 10) Evaluate recognition (CER/WER)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761499585.3536549"
      },
      "source": [
        "\n",
        "%%bash\n",
        "set -euo pipefail\n",
        "ketos test -f alto /content/models/rec_best.mlmodel @/content/lists/val.txt\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761499585.3536904"
      },
      "source": [
        "## 11) Package models for download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761499585.3537147"
      },
      "source": [
        "\n",
        "!cd /content/models && ls -lh && zip -r ../trained_models.zip . && cd /content\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell_1761499585.353738"
      },
      "source": [
        "## 12) Optional â€” Upload to msia.escriptorium.fr via API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cell_1761499585.3537624"
      },
      "source": [
        "\n",
        "# UI upload (My Models â†’ Upload) is simplest.\n",
        "# Programmatic upload (if supported by your instance):\n",
        "MSIA_URL   = \"https://msia.escriptorium.fr\"\n",
        "API_TOKEN  = \"PASTE_YOUR_TOKEN_HERE\"   # keep secret or leave blank\n",
        "MODEL_PATH = \"/content/models/rec_best.mlmodel\"   # or seg_best.mlmodel\n",
        "MODEL_NAME = \"rec_best\"\n",
        "\n",
        "if API_TOKEN and API_TOKEN != \"PASTE_YOUR_TOKEN_HERE\":\n",
        "    import requests\n",
        "    headers = {\"Authorization\": f\"Token {API_TOKEN}\"}\n",
        "    files = {\"file\": (MODEL_NAME + \".mlmodel\", open(MODEL_PATH, \"rb\"), \"application/octet-stream\")}\n",
        "    data  = {\"name\": MODEL_NAME}\n",
        "    resp = requests.post(f\"{MSIA_URL}/api/models/\", headers=headers, files=files, data=data)\n",
        "    print(\"Status:\", resp.status_code)\n",
        "    try:\n",
        "        print(resp.json())\n",
        "    except Exception:\n",
        "        print(resp.text[:800])\n",
        "else:\n",
        "    print(\"Skipping API upload. Use the UI or paste a valid API token.\")\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ]
}